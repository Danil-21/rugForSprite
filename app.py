import os
import re
import json
import logging
from typing import List, Optional, Dict, Tuple
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from datetime import datetime
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.chat_models import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from rag_config import VECTOR_DB_DIR

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =====================
# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
# =====================
class Question(BaseModel):
    question: str

class Source(BaseModel):
    source: Optional[str] = None
    snippet: str
    relevance: Optional[float] = None
    url: Optional[str] = None  # –î–æ–±–∞–≤–ª—è–µ–º URL –¥–ª—è —Å—Å—ã–ª–æ–∫
    document_type: Optional[str] = None

class Answer(BaseModel):
    answer: str
    sources: List[Source]
    priority: str  # low, medium, high
    route_to: Optional[str] = None  # L1 / L2 / L3
    judge_reason: str
    confidence: Optional[float] = Field(None, ge=0.0, le=1.0)
    confidence_details: Optional[Dict] = None  # –î–µ—Ç–∞–ª–∏ —Ä–∞—Å—á–µ—Ç–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏

# =====================
# –£—Ç–∏–ª–∏—Ç—ã –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
# =====================
STOP_WORDS = {
    "—á—Ç–æ", "–∫–∞–∫", "–∫–∞–∫–∏–µ", "–¥–ª—è", "—á–µ–≥–æ", "—ç—Ç–æ", "–ø—Ä–æ", "–æ",
    "–∏", "–∏–ª–∏", "–∞", "–≤", "–Ω–∞", "–ø–æ", "–∏–∑", "–ª–∏", "–∂–µ", "–Ω–µ",
    "–Ω–æ", "–∑–∞", "—É", "–æ—Ç", "–¥–æ", "–±–µ–∑", "–ø–æ–¥", "–Ω–∞–¥", "–ø—Ä–∏",
    "–∫", "—Å", "—Å–æ", "–≤–æ", "–æ–±", "—Ç–æ", "—Ç–∞–∫", "–≤–æ—Ç", "—Ç—É—Ç"
}

# –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å —Ä–∞–∑–¥–µ–ª–∞–º–∏ —Å–∞–π—Ç–∞ –°–±–µ—Ä–∞
SBER_SITE_SECTIONS = {
    "–∫–∞—Ä—Ç–∞": "https://www.sberbank.ru/ru/person/bank_cards",
    "–≤–∫–ª–∞–¥": "https://www.sberbank.ru/ru/person/contributions",
    "–∫—Ä–µ–¥–∏—Ç": "https://www.sberbank.ru/ru/person/credits",
    "–∏–∏—Å": "https://www.sberbank.ru/ru/person/investments/iis",
    "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏": "https://www.sberbank.ru/ru/person/investments",
    "–∏–ø–æ—Ç–µ–∫–∞": "https://www.sberbank.ru/ru/person/credits/mortgage",
    "–ø–µ—Ä–µ–≤–æ–¥": "https://www.sberbank.ru/ru/person/transfer",
    "–ø–ª–∞—Ç–µ–∂": "https://www.sberbank.ru/ru/person/payments",
    "–æ–Ω–ª–∞–π–Ω": "https://www.sberbank.ru/ru/person/sberbankonline",
    "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ": "https://www.sberbank.ru/ru/person/sberbankonline/mobileapp",
    "–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ": "https://www.sberbank.ru/ru/person/sberbankonline/restore",
    "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å": "https://www.sberbank.ru/ru/person/security",
    "–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ": "https://www.sberbank.ru/ru/person/security/fraud",
    "–æ—Ç–¥–µ–ª–µ–Ω–∏–µ": "https://www.sberbank.ru/ru/person/branch",
    "–±–∞–Ω–∫–æ–º–∞—Ç": "https://www.sberbank.ru/ru/person/atm",
    "—Ç–∞—Ä–∏—Ñ": "https://www.sberbank.ru/ru/person/tariffs",
    "–∫–æ–º–∏—Å—Å–∏—è": "https://www.sberbank.ru/ru/person/tariffs",
    "faq": "https://www.sberbank.ru/ru/person/faq",
    "–ø–æ–¥–¥–µ—Ä–∂–∫–∞": "https://www.sberbank.ru/ru/person/help",
    "–∫–æ–Ω—Ç–∞–∫—Ç—ã": "https://www.sberbank.ru/ru/person/contacts",
}

# –ë–∞–∑–æ–≤—ã–µ URL –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
DOCUMENT_URL_MAPPING = {
    # –ü—Ä–∏–º–µ—Ä —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ —Å URL
    "–∞–∫—Ü–∏—è_–∏–Ω–≤–µ—Å—Ç–∏—Ä—É–π —Å–æ —Å–±–µ—Ä–±–∞–Ω–∫–æ–º": "https://www.sberbank.ru/ru/person/investments/promotions",
    "–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–∞": "https://www.sberbank.ru/ru/person/sberbankonline/restore",
    "–æ–±—ã–∫–Ω–æ–≤–µ–Ω–Ω–∞—è –∞–∫—Ü–∏—è": "https://www.sberbank.ru/ru/person/investments/securities",
}

HIGH_PRIORITY_TERMS = {
    "–¥–µ–Ω—å–≥–∏", "—Å—á–µ—Ç", "–∫–∞—Ä—Ç–∞", "–ø–µ—Ä–µ–≤–æ–¥", "–ø–ª–∞—Ç–µ–∂", "—Å–ø–∏—Å–∞–Ω–∏–µ", "–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ",
    "–≤–∑–ª–æ–º", "–∫—Ä–∞–∂–∞", "–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞", "–∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω", "–Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", "–æ—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞",
    "–ø–æ—Ç–µ—Ä—è–ª", "—É–∫—Ä–∞–ª–∏", "–Ω–µ—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π", "–∞—Ä–µ—Å—Ç", "–∞—Ä–µ—Å—Ç–æ–≤–∞–Ω", "–∫–æ–Ω—Ñ–∏—Å–∫–∞—Ü–∏—è",
    "–∞—Ä–µ—Å—Ç —Å—á–µ—Ç–∞", "–∑–∞–º–æ—Ä–æ–∂–µ–Ω", "—Å—Ä–æ—á–Ω–æ", "—ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ", "–∫—Ä–∏—Ç–∏—á–Ω–æ", "—É–≥—Ä–æ–∑–∞",
    "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "–ø–∞—Ä–æ–ª—å", "–≤—Ö–æ–¥", "–≤–∑–ª–æ–º–∞–ª–∏", "—Ñ–∏—à–∏–Ω–≥", "–æ–±–º–∞–Ω"
}

MEDIUM_PRIORITY_TERMS = {
    "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç", "–æ—à–∏–±–∫–∞", "—Å–±–æ–π", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã", "–Ω–µ –∑–∞—Ö–æ–¥–∏—Ç",
    "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "–æ–Ω–ª–∞–π–Ω", "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–±–∞–Ω–∫", "–º–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "—Å–∞–π—Ç",
    "–¥–æ—Å—Ç—É–ø", "–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è", "–≤—Ö–æ–¥", "–ª–æ–≥–∏–Ω", "–ø–∞—Ä–æ–ª—å", "–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
    "–∑–∞–±—ã–ª", "—É—Ç–µ—Ä—è", "—Å–º–µ–Ω–∞", "–Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞", "email", "–∫–æ–Ω—Ç–∞–∫—Ç—ã",
    "–Ω–∞—Å—Ç—Ä–æ–π–∫–∏", "–æ–ø–µ—Ä–∞—Ü–∏—è", "—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è", "–æ—Ç–∫–∞–∑", "–æ—Ç–∫–ª–æ–Ω–µ–Ω–æ", "–Ω–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç"
}

LOW_PRIORITY_TERMS = {
    "–∫–∞–∫ —É–∑–Ω–∞—Ç—å", "–≥–¥–µ –Ω–∞–π—Ç–∏", "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è", "—Å–ø—Ä–∞–≤–∫–∞", "–æ–±—É—á–µ–Ω–∏–µ",
    "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", "—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ", "—á–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ", "faq", "–≤–æ–ø—Ä–æ—Å",
    "–æ—Ç–≤–µ—Ç", "–¥–æ–∫—É–º–µ–Ω—Ç", "—Ä–µ–∫–≤–∏–∑–∏—Ç—ã", "–∞–¥—Ä–µ—Å", "—Ç–µ–ª–µ—Ñ–æ–Ω", "–≥—Ä–∞—Ñ–∏–∫",
    "—Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã", "–æ—Ç–¥–µ–ª–µ–Ω–∏–µ", "–±–∞–Ω–∫–æ–º–∞—Ç", "—É—Å–ª–æ–≤–∏—è", "—Ç–∞—Ä–∏—Ñ",
    "–∫–æ–º–∏—Å—Å–∏—è", "–ø—Ä–æ—Ü–µ–Ω—Ç", "—Å—Ç–∞–≤–∫–∞", "–∫—Ä–µ–¥–∏—Ç", "–≤–∫–ª–∞–¥", "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏"
}

def extract_core_terms(text: str) -> set:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    words = re.findall(r"[a-z–∞-—è—ë0-9]+", text.lower())
    return {w for w in words if len(w) >= 3 and w not in STOP_WORDS}

def get_sber_site_url(question: str) -> Optional[str]:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ä–∞–∑–¥–µ–ª —Å–∞–π—Ç–∞ –°–±–µ—Ä–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞"""
    question_lower = question.lower()
    
    # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –≤–æ–ø—Ä–æ—Å–µ
    for keyword, url in SBER_SITE_SECTIONS.items():
        if keyword in question_lower:
            return url
    
    return None

def extract_urls_from_text(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    url_pattern = r'https?://(?:www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}\b[-a-zA-Z0-9()@:%_\+.~#?&//=]*'
    urls = re.findall(url_pattern, text)
    return urls

def generate_document_url(source_path: str, content: str) -> Optional[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–ª–∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç URL –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    if not source_path:
        return None
    
    filename = os.path.basename(source_path).lower()
    
    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ URL –≤ —Å–∞–º–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ
    urls_in_content = extract_urls_from_text(content[:1000])  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—á–∞–ª–æ
    if urls_in_content:
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ URL –°–±–µ—Ä–∞
        sber_urls = [url for url in urls_in_content if 'sberbank' in url]
        if sber_urls:
            return sber_urls[0]
    
    # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    for doc_key, url in DOCUMENT_URL_MAPPING.items():
        if doc_key.lower() in filename:
            return url
    
    # –ï—Å–ª–∏ —ç—Ç–æ HTML —Ñ–∞–π–ª, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ —ç—Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–∞–π—Ç–∞
    if source_path.endswith('.html'):
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–π URL –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        html_name = os.path.splitext(filename)[0]
        for keyword, url in SBER_SITE_SECTIONS.items():
            if keyword in html_name:
                return url
    
    return None

def is_valid_sber_url(url: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL –¥–æ–ø—É—Å—Ç–∏–º—ã–º URL –°–±–µ—Ä–∞"""
    if not url:
        return False
    
    valid_domains = ['sberbank.ru', 'sberbank.com', 'sber.ru']
    return any(domain in url for domain in valid_domains)

def context_supports_question(context: str, question: str, min_matches: int = 2) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –≤–æ–ø—Ä–æ—Å–∞"""
    context_lower = context.lower()
    terms = extract_core_terms(question)
    
    if not terms:
        return True
    
    matches = sum(1 for term in terms if term in context_lower)
    return matches >= min_matches

def calculate_confidence(
    docs_with_scores: List[Tuple],
    question: str,
    answer: str,
    context: str
) -> Tuple[float, Dict]:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–∞ –≤ –æ—Ç–≤–µ—Ç–µ
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - confidence_score (0.0-1.0)
    - confidence_details (–¥–µ—Ç–∞–ª–∏ —Ä–∞—Å—á–µ—Ç–∞)
    """
    details = {
        "calculation_time": datetime.now().isoformat(),
        "factors": {}
    }
    
    if not docs_with_scores:
        details["factors"]["no_documents"] = "–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        return 0.0, details
    
    # –§–∞–∫—Ç–æ—Ä 1: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–≤–µ—Å 40%)
    relevancy_scores = [1.0 - score for _, score in docs_with_scores]
    avg_relevancy = sum(relevancy_scores) / len(relevancy_scores)
    details["factors"]["document_relevancy"] = {
        "average": avg_relevancy,
        "scores": relevancy_scores,
        "count": len(docs_with_scores)
    }
    
    relevancy_factor = avg_relevancy * 0.4
    
    # –§–∞–∫—Ç–æ—Ä 2: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–≤–µ—Å 20%)
    good_docs = sum(1 for score in relevancy_scores if score > 0.7)
    doc_count_factor = min(good_docs / 3, 1.0) * 0.2
    details["factors"]["document_count"] = {
        "good_docs": good_docs,
        "total_docs": len(docs_with_scores),
        "factor": doc_count_factor
    }
    
    # –§–∞–∫—Ç–æ—Ä 3: –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ (–≤–µ—Å 20%)
    question_terms = extract_core_terms(question)
    answer_terms = extract_core_terms(answer)
    
    if question_terms:
        term_overlap = len(question_terms.intersection(answer_terms)) / len(question_terms)
    else:
        term_overlap = 0.5
    
    term_factor = term_overlap * 0.2
    details["factors"]["term_overlap"] = {
        "question_terms": list(question_terms),
        "answer_terms": list(answer_terms),
        "overlap_ratio": term_overlap,
        "factor": term_factor
    }
    
    # –§–∞–∫—Ç–æ—Ä 4: –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞ (–≤–µ—Å 20%)
    answer_quality = 0.0
    answer_lower = answer.lower()
    
    # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    positive_indicators = [
        len(answer) > 50,  # –û—Ç–≤–µ—Ç –Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
        not any(phrase in answer_lower for phrase in [
            "–Ω–µ –∑–Ω–∞—é", "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç", "–Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å"
        ]),
        any(word in answer_lower for word in [
            "—à–∞–≥", "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", "–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ", "—Ç—Ä–µ–±—É–µ—Ç—Å—è", "–º–æ–∂–Ω–æ"
        ])
    ]
    
    answer_quality = sum(positive_indicators) / len(positive_indicators)
    quality_factor = answer_quality * 0.2
    details["factors"]["answer_quality"] = {
        "indicators": positive_indicators,
        "quality_score": answer_quality,
        "factor": quality_factor
    }
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    confidence_score = relevancy_factor + doc_count_factor + term_factor + quality_factor
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω
    confidence_score = max(0.0, min(1.0, confidence_score))
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é
    if confidence_score > 0.8:
        interpretation = "–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
    elif confidence_score > 0.6:
        interpretation = "–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
    elif confidence_score > 0.3:
        interpretation = "–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
    else:
        interpretation = "–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
    
    details["interpretation"] = interpretation
    details["final_score"] = confidence_score
    
    return confidence_score, details

def get_question_priority_keywords(question: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (–¥–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤)"""
    q_lower = question.lower()
    
    if any(term in q_lower for term in HIGH_PRIORITY_TERMS):
        return "high"
    
    if any(term in q_lower for term in MEDIUM_PRIORITY_TERMS):
        return "medium"
    
    if any(term in q_lower for term in LOW_PRIORITY_TERMS):
        return "low"
    
    return "low"

# =====================
# –ü—Ä–æ–º–ø—Ç—ã (–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤)
# =====================
PRIORITY_PROMPT = ChatPromptTemplate.from_messages([
    (
        "system",
        """–¢—ã ‚Äî —Å–∏—Å—Ç–µ–º–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–±—Ä–∞—â–µ–Ω–∏–π –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ —Å–ª—É–∂–±—É –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –°–±–µ—Ä–±–∞–Ω–∫–∞.
–û–ø—Ä–µ–¥–µ–ª–∏ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å –≤–æ–ø—Ä–æ—Å–∞ –ö–õ–ò–ï–ù–¢–ê.

HIGH (–≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) ‚Äî –≤—Å—ë, —á—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å –¥–µ–Ω—å–≥–∞–º–∏, —Å—á–µ—Ç–∞–º–∏, –∫–∞—Ä—Ç–∞–º–∏, –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏, –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ–º, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é, –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞–º–∏, —Å—Ä–æ—á–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏, –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–º–∏/—É–∫—Ä–∞–¥–µ–Ω–Ω—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏, –Ω–µ—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–ø–∏—Å–∞–Ω–∏—è–º–∏.

MEDIUM (—Å—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) ‚Äî —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã: –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, —Å–∞–π—Ç, –æ—à–∏–±–∫–∏ –≤—Ö–æ–¥–∞, –ø—Ä–æ–±–ª–µ–º—ã —Å –¥–æ—Å—Ç—É–ø–æ–º, —Å–±–æ–∏ –≤ —Ä–∞–±–æ—Ç–µ —Å–µ—Ä–≤–∏—Å–æ–≤, –≤–æ–ø—Ä–æ—Å—ã –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º, –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–∞.

LOW (–Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) ‚Äî –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã: —Å–ø—Ä–∞–≤–∫–∞, –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã, –∞–¥—Ä–µ—Å–∞ –æ—Ç–¥–µ–ª–µ–Ω–∏–π, —Ç–∞—Ä–∏—Ñ—ã, —É—Å–ª–æ–≤–∏—è —É—Å–ª—É–≥, –æ–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã.

–û—Ç–≤–µ—Ç—å –û–î–ù–ò–ú —Å–ª–æ–≤–æ–º: LOW, MEDIUM –∏–ª–∏ HIGH."""
    ),
    ("human", "–í–û–ü–†–û–° –ö–õ–ò–ï–ù–¢–ê: {question}")
])

JUDGE_PROMPT = ChatPromptTemplate.from_messages([
    (
        "system",
        """–¢—ã ‚Äî AI-—Å—É–¥—å—è —Å–ª—É–∂–±—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –°–±–µ—Ä–±–∞–Ω–∫–∞ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å:
1. –ù–∞—Å–∫–æ–ª—å–∫–æ –ø–æ–ª–Ω–æ –∏ –ø–æ–ª–µ–∑–Ω–æ –æ—Ç–≤–µ—Ç–∏–ª –∞–≥–µ–Ω—Ç
2. –ù—É–∂–Ω–∞ –ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–º–æ—â—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –ü–û–°–õ–ï –æ—Ç–≤–µ—Ç–∞ –∞–≥–µ–Ω—Ç–∞

–ù–û–í–´–ï –ü–†–ê–í–ò–õ–ê:
1. –ê–≥–µ–Ω—Ç –í–°–ï–ì–î–ê –ø—ã—Ç–∞–µ—Ç—Å—è –æ—Ç–≤–µ—Ç–∏—Ç—å, –µ—Å–ª–∏ –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
2. –ü–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ü–µ–Ω–∏–≤–∞–µ–º: –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ —ç—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∏–ª–∏ –Ω—É–∂–µ–Ω —Å–æ—Ç—Ä—É–¥–Ω–∏–∫
3. –°–æ—Ç—Ä—É–¥–Ω–∏–∫ –Ω—É–∂–µ–Ω –µ—Å–ª–∏:
   - –û—Ç–≤–µ—Ç –Ω–µ–ø–æ–ª–Ω—ã–π –∏–ª–∏ –Ω–µ–ø–æ–Ω—è—Ç–Ω—ã–π
   - –¢—Ä–µ–±—É—é—Ç—Å—è –¥–µ–π—Å—Ç–≤–∏—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ (—Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞, –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–ø–µ—Ä–∞—Ü–∏–π)
   - –ö–ª–∏–µ–Ω—Ç—É –Ω—É–∂–Ω–æ –æ–±—â–µ–Ω–∏–µ —Å –∂–∏–≤—ã–º —á–µ–ª–æ–≤–µ–∫–æ–º
   - –í–æ–ø—Ä–æ—Å —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω—ã–π –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞

–í–µ—Ä–Ω–∏ –°–¢–†–û–ì–û JSON:

{
  "helped": true | false,
  "priority": "low" | "medium" | "high",
  "route_to": "L1" | "L2" | "L3" | null,
  "reason": "–∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º"
}

–í–∞–∂–Ω–æ: route_to = null –µ—Å–ª–∏ –∞–≥–µ–Ω—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ—à–∏–ª –≤–æ–ø—Ä–æ—Å.
route_to != null –µ—Å–ª–∏ –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ –∞–≥–µ–Ω—Ç–∞ –Ω—É–∂–Ω—ã –¥–µ–π—Å—Ç–≤–∏—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞."""
    ),
    (
        "human",
        """–í–û–ü–†–û–° –ö–õ–ò–ï–ù–¢–ê:
{question}

–û–¢–í–ï–¢ –ê–ì–ï–ù–¢–ê:
{answer}

–ö–û–ù–¢–ï–ö–°–¢ (–Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –æ—Ç–≤–µ—á–∞–ª –∞–≥–µ–Ω—Ç):
{context}"""
    )
])

ANSWER_PROMPT = ChatPromptTemplate.from_messages([
    (
        "system",
        """–¢—ã ‚Äî AI-–∞–≥–µ–Ω—Ç –ø–µ—Ä–≤–æ–π –ª–∏–Ω–∏–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –°–±–µ—Ä–±–∞–Ω–∫–∞ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ–≥–∞—Ç—å –∫–ª–∏–µ–Ω—Ç–∞–º —Ä–µ—à–∞—Ç—å –∏—Ö –≤–æ–ø—Ä–æ—Å—ã, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.

–í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
1. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
2. –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω—ã–º –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º
3. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å URL –Ω–∞ —Å–∞–π—Ç –°–±–µ—Ä–∞ - –≤–∫–ª—é—á–∏ –∏—Ö –≤ –æ—Ç–≤–µ—Ç
4. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ - —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏
5. –î–∞–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–∑ –∏–º–µ—é—â–µ–π—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

–°–¢–ò–õ–¨ –û–ë–©–ï–ù–ò–Ø:
- –í–µ–∂–ª–∏–≤–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ
- –ü—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
- –° —ç–º–ø–∞—Ç–∏–µ–π
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∏ –ø–æ –¥–µ–ª—É
- –ï—Å–ª–∏ –µ—Å—Ç—å —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–∞–π—Ç - –¥–æ–±–∞–≤—å –∏—Ö –≤ –∫–æ–Ω—Ü–µ"""
    ),
    (
        "human",
        """–ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô –°–ë–ï–†–ë–ê–ù–ö–ê:
{context}

–í–û–ü–†–û–° –ö–õ–ò–ï–ù–¢–ê:
{question}

–¢–í–û–ô –û–¢–í–ï–¢ –ö–õ–ò–ï–ù–¢–£ (–≤–∫–ª—é—á–∏ —Å—Å—ã–ª–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ):"""
    )
])

EXPANSION_PROMPT = ChatPromptTemplate.from_messages([
    (
        "system",
        """–ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞ 2-3 —Å–ø–æ—Å–æ–±–∞–º–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.
–°–æ—Ö—Ä–∞–Ω–∏ –æ—Å–Ω–æ–≤–Ω–æ–π —Å–º—ã—Å–ª, –Ω–µ –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—ã–µ —Ñ–∞–∫—Ç—ã.
–ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Å—Ç—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏."""
    ),
    ("human", "–í–û–ü–†–û–° –ö–õ–ò–ï–ù–¢–ê: {question}")
])

# =====================
# –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# =====================
def detect_priority(llm, question: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤–æ–ø—Ä–æ—Å–∞ –∫–ª–∏–µ–Ω—Ç–∞"""
    try:
        result = (PRIORITY_PROMPT | llm | StrOutputParser()).invoke(
            {"question": question}
        )
        result = result.strip().upper()
        if result in {"LOW", "MEDIUM", "HIGH"}:
            logger.info(f"LLM –æ–ø—Ä–µ–¥–µ–ª–∏–ª –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {result}")
            return result
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ LLM: {e}")
    
    priority = get_question_priority_keywords(question).upper()
    logger.info(f"Keyword –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority}")
    return priority

def judge_answer(llm, question: str, answer: str, context: str, priority: str) -> dict:
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç: –ø–æ–º–æ–≥ –ª–∏ –∞–≥–µ–Ω—Ç –∏ –Ω—É–∂–µ–Ω –ª–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –ü–û–°–õ–ï –æ—Ç–≤–µ—Ç–∞"""
    parser = JsonOutputParser()
    chain = JUDGE_PROMPT | llm | parser
    
    try:
        result = chain.invoke({
            "question": question,
            "answer": answer,
            "context": context[:2000]
        })
        
        if not isinstance(result, dict):
            result = {}
        
        answer_lower = answer.lower()
        if "helped" not in result:
            not_helpful_phrases = [
                "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç", "–Ω–µ –∑–Ω–∞—é", "–Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å", 
                "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö", "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
            ]
            result["helped"] = not any(phrase in answer_lower for phrase in not_helpful_phrases)
        
        if "priority" not in result:
            result["priority"] = priority.lower()
        
        if "route_to" not in result:
            if not result.get("helped", True):
                if result["priority"] == "high":
                    result["route_to"] = "L3"
                elif result["priority"] == "medium":
                    result["route_to"] = "L2"
                else:
                    result["route_to"] = "L1"
            else:
                needs_human = (
                    result["priority"] == "high" and 
                    any(word in answer_lower for word in ["–ø–æ–∑–≤–æ–Ω–∏—Ç–µ", "–æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å", "—Å–æ—Ç—Ä—É–¥–Ω–∏–∫"])
                ) or (
                    result["priority"] == "medium" and
                    any(word in answer_lower for word in ["–ø–æ–∑–≤–æ–Ω–∏—Ç–µ –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É", "–æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –æ–ø–µ—Ä–∞—Ç–æ—Ä—É"])
                )
                
                if needs_human:
                    result["route_to"] = "L3" if result["priority"] == "high" else "L2"
                else:
                    result["route_to"] = None
        
        if "reason" not in result:
            if result.get("helped", True):
                if result.get("route_to"):
                    result["reason"] = "–ê–≥–µ–Ω—Ç –¥–∞–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –Ω–æ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π –Ω—É–∂–µ–Ω —Å–æ—Ç—Ä—É–¥–Ω–∏–∫"
                else:
                    result["reason"] = "–ê–≥–µ–Ω—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–≤–µ—Ç–∏–ª –Ω–∞ –≤–æ–ø—Ä–æ—Å"
            else:
                result["reason"] = "–ê–≥–µ–Ω—Ç –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞"
        
        return result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –æ—Ç–≤–µ—Ç–∞: {e}")
        return {
            "helped": True,
            "priority": priority.lower(),
            "route_to": "L2" if priority == "HIGH" else None,
            "reason": "–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –∞–≥–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∏–ª"
        }

def needs_human_after_answer(question: str, answer: str, priority: str) -> bool:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–µ–Ω –ª–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –ü–û–°–õ–ï —Ç–æ–≥–æ –∫–∞–∫ –∞–≥–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∏–ª"""
    answer_lower = answer.lower()
    
    if priority == "high":
        if "–∫–∞–∫ —É–∑–Ω–∞—Ç—å" in question.lower() or "–≥–¥–µ –Ω–∞–π—Ç–∏" in question.lower():
            return False
        return True
    
    if priority == "medium":
        if any(phrase in answer_lower for phrase in [
            "–ø–æ–∑–≤–æ–Ω–∏—Ç–µ", "–æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫", "—Å–≤—è–∂–∏—Ç–µ—Å—å —Å", "–ø–æ–∑–≤–æ–Ω–∏—Ç—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É"
        ]):
            return True
    
    return False

def generate_enhanced_answer(original_answer: str, question: str, priority: str, 
                           helped: bool, sources: List[Source]) -> str:
    """–£–ª—É—á—à–∞–µ—Ç –æ—Ç–≤–µ—Ç –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞, –¥–æ–±–∞–≤–ª—è—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ"""
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ URL –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    source_urls = []
    for source in sources:
        if source.url and is_valid_sber_url(source.url):
            source_urls.append(source.url)
    
    # –¢–∞–∫–∂–µ –ø–æ–ª—É—á–∞–µ–º –æ–±—â–∏–π URL –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞
    question_url = get_sber_site_url(question)
    if question_url and question_url not in source_urls:
        source_urls.append(question_url)
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    source_urls = list(set(source_urls))
    
    enhanced_answer = original_answer
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    if source_urls and helped:
        links_text = "\n\nüîó **–ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏:**\n"
        for i, url in enumerate(source_urls[:3], 1):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 3 —Å—Å—ã–ª–∫–∞–º–∏
            links_text += f"{i}. {url}\n"
        enhanced_answer += links_text
    
    if not helped:
        if priority == "high":
            enhanced_answer += (
                "\n\nüî¥ –ü–æ—Å–∫–æ–ª—å–∫—É —ç—Ç–æ —Å—Ä–æ—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å, —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é –∏–ª–∏ –¥–µ–Ω—å–≥–∞–º–∏, "
                "—Ä–µ–∫–æ–º–µ–Ω–¥—É—é –ù–ï–ú–ï–î–õ–ï–ù–ù–û –ø–æ–∑–≤–æ–Ω–∏—Ç—å –Ω–∞ –≥–æ—Ä—è—á—É—é –ª–∏–Ω–∏—é –°–±–µ—Ä–±–∞–Ω–∫–∞: 900."
            )
        elif priority == "medium":
            enhanced_answer += (
                "\n\n–î–ª—è —Ä–µ—à–µ–Ω–∏—è —ç—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–º–æ—â—å —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏. "
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ —Å–ª—É–∂–±—É –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –°–±–µ—Ä–±–∞–Ω–∫–∞ –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É 900."
            )
    
    elif priority == "high" and needs_human_after_answer(question, original_answer, priority):
        enhanced_answer += (
            "\n\n‚ö†Ô∏è **–ü–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–æ–∑–≤–æ–Ω–∏—Ç–µ –Ω–∞ –≥–æ—Ä—è—á—É—é –ª–∏–Ω–∏—é 900 "
            "–¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–æ—Ü–µ–¥—É—Ä—ã.**"
        )
    
    elif priority == "medium" and needs_human_after_answer(question, original_answer, priority):
        enhanced_answer += (
            "\n\nüìû –ï—Å–ª–∏ —É –≤–∞—Å –æ—Å—Ç–∞–ª–∏—Å—å –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –Ω—É–∂–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–º–æ—â—å, "
            "–æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É 900."
        )
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ–∂–ª–∏–≤–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
    import random
    endings = [
        "\n\n–ù–∞–¥–µ—é—Å—å, —ç—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –±—ã–ª–∞ –ø–æ–ª–µ–∑–Ω–æ–π!",
        "\n\n–ï—Å–ª–∏ –Ω—É–∂–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–º–æ—â—å - –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å!",
        "\n\n–ñ–µ–ª–∞—é —É–¥–∞—á–Ω–æ–≥–æ –¥–Ω—è!",
        "\n\n–í—Å–µ–≥–æ –¥–æ–±—Ä–æ–≥–æ!"
    ]
    
    ending = random.choice(endings)
    return enhanced_answer + ending

def format_sources(docs_with_scores, max_sources: int = 3) -> List[Source]:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –∫–ª–∏–µ–Ω—Ç—É —Å URL"""
    sources = []
    
    for doc, score in docs_with_scores[:max_sources]:
        snippet = doc.page_content[:300].strip()
        if len(doc.page_content) > 300:
            snippet += "..."
        
        source_path = doc.metadata.get("source", "")
        doc_type = doc.metadata.get("type", "document")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º URL –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
        doc_url = generate_document_url(source_path, doc.page_content)
        
        if doc_type == "pdf":
            source_display = "–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –°–±–µ—Ä–±–∞–Ω–∫–∞"
        elif doc_type == "html":
            source_display = "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å —Å–∞–π—Ç–∞ –°–±–µ—Ä–±–∞–Ω–∫–∞"
        else:
            source_display = "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –°–±–µ—Ä–±–∞–Ω–∫–∞"
        
        sources.append(Source(
            source=source_display,
            snippet=snippet,
            relevance=1.0 - score,
            url=doc_url if is_valid_sber_url(doc_url) else None,
            document_type=doc_type
        ))
    
    return sources

def log_confidence_metrics(question: str, confidence: float, details: Dict):
    """–õ–æ–≥–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "question": question,
        "confidence": confidence,
        "details": details,
        "interpretation": details.get("interpretation", "unknown")
    }
    
    # –õ–æ–≥–∏—Ä—É–µ–º –≤ –∫–æ–Ω—Å–æ–ª—å
    logger.info(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–∞: {confidence:.2%} - {details.get('interpretation', 'unknown')}")
    logger.debug(f"–î–µ—Ç–∞–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {json.dumps(details, ensure_ascii=False, indent=2)}")
    
    # –¢–∞–∫–∂–µ –º–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
    try:
        log_file = "confidence_metrics.log"
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ñ–∞–π–ª: {e}")

def no_answer(priority: str, found_docs: bool = False) -> Answer:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –∫–æ–≥–¥–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç"""
    
    if found_docs:
        if priority == "HIGH":
            answer_text = (
                "–Ø –Ω–∞—à–µ–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –≤–∞—à–µ–π —Ç–µ–º–µ, –Ω–æ –Ω–µ —Å–º–æ–≥ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç. "
                "–ü–æ—Å–∫–æ–ª—å–∫—É –≤–æ–ø—Ä–æ—Å —Å—Ä–æ—á–Ω—ã–π, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –ø–æ–∑–≤–æ–Ω–∏—Ç–µ –Ω–∞ –≥–æ—Ä—è—á—É—é –ª–∏–Ω–∏—é: 900."
            )
            route = "L3"
        elif priority == "MEDIUM":
            answer_text = (
                "–ü–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –Ω–æ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–º–æ—â—å —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞. "
                "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É 900."
            )
            route = "L2"
        else:
            answer_text = (
                "–ü–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É –µ—Å—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –Ω–æ –æ–Ω–∞ –Ω–µ–ø–æ–ª–Ω–∞—è. "
                "–í—ã –º–æ–∂–µ—Ç–µ —É—Ç–æ—á–Ω–∏—Ç—å –Ω–∞ —Å–∞–π—Ç–µ –°–±–µ—Ä–±–∞–Ω–∫–∞ –∏–ª–∏ –ø–æ–∑–≤–æ–Ω–∏—Ç—å –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É 900."
            )
            route = "L1"
    else:
        if priority == "HIGH":
            answer_text = (
                "üî¥ –°—Ä–æ—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å! –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–µ—Ç –≤ –º–æ–µ–π –±–∞–∑–µ. "
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ù–ï–ú–ï–î–õ–ï–ù–ù–û –ø–æ–∑–≤–æ–Ω–∏—Ç–µ –Ω–∞ –≥–æ—Ä—è—á—É—é –ª–∏–Ω–∏—é –°–±–µ—Ä–±–∞–Ω–∫–∞: 900."
            )
            route = "L3"
        elif priority == "MEDIUM":
            answer_text = (
                "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É –Ω–µ—Ç –≤ –º–æ–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π. "
                "–î–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ —Å–ª—É–∂–±—É –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É 900."
            )
            route = "L2"
        else:
            answer_text = (
                "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —É –º–µ–Ω—è –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É. "
                "–í—ã –º–æ–∂–µ—Ç–µ –Ω–∞–π—Ç–∏ –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –Ω–∞ —Å–∞–π—Ç–µ –°–±–µ—Ä–±–∞–Ω–∫–∞ www.sberbank.ru "
                "–∏–ª–∏ –ø–æ–∑–≤–æ–Ω–∏—Ç—å –≤ —Å–ø—Ä–∞–≤–æ—á–Ω—É—é —Å–ª—É–∂–±—É –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É 900."
            )
            route = "L1"
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –Ω–∏–∑–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è no_answer
    confidence, details = calculate_confidence([], question="", answer=answer_text, context="")
    
    # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
    log_confidence_metrics("", confidence, details)
    
    return Answer(
        answer=answer_text,
        sources=[],
        priority=priority.lower(),
        route_to=route,
        judge_reason="–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω–∞—è –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π",
        confidence=confidence,
        confidence_details=details
    )

def expand_query(llm, question: str) -> List[str]:
    """–†–∞—Å—à–∏—Ä—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞"""
    expansions = [question]
    
    try:
        expansions_raw = (EXPANSION_PROMPT | llm | StrOutputParser()).invoke(
            {"question": question}
        )
        
        for line in expansions_raw.split('\n'):
            line = line.strip()
            if line and len(line) > 10:
                clean_line = re.sub(r'^[\d\-‚Ä¢\.\)\s]+', '', line)
                if clean_line and clean_line != question:
                    expansions.append(clean_line)
        
        expansions = list(dict.fromkeys(expansions))[:4]
        
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
    
    return expansions

# =====================
# –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ FastAPI
# =====================
def create_app() -> FastAPI:
    app = FastAPI(
        title="SberBank Client Support AI Agent",
        version="2.3.0",
        description="AI-–∞–≥–µ–Ω—Ç –ø–µ—Ä–≤–æ–π –ª–∏–Ω–∏–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –°–±–µ—Ä–±–∞–Ω–∫–∞",
    )
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI-–∞–≥–µ–Ω—Ç–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤...")
    
    try:
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        vectordb = FAISS.load_local(
            str(VECTOR_DB_DIR),
            embeddings,
            allow_dangerous_deserialization=True,
        )
        logger.info("–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
        raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π: {e}")
    
    try:
        llm = ChatOllama(
            model="llama3.2",
            temperature=0.1,
            seed=42,
            timeout=30.0
        )
        logger.info("AI –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ AI: {e}")
        raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ AI –º–æ–¥–µ–ª–∏: {e}")
    
    @app.get("/")
    async def root():
        return {
            "service": "AI Agent - First Line Support for SberBank Clients",
            "version": "2.3.0",
            "status": "active",
            "features": [
                "–û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∫–ª–∏–µ–Ω—Ç–æ–≤",
                "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏",
                "–°—Å—ã–ª–∫–∏ –Ω–∞ —Å–∞–π—Ç –°–±–µ—Ä–±–∞–Ω–∫–∞",
                "–£–º–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è",
                "–ü–æ–¥—Ä–æ–±–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞"
            ],
            "endpoints": {
                "ask": "POST /ask - –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ—Ç –ª–∏—Ü–∞ –∫–ª–∏–µ–Ω—Ç–∞",
                "health": "GET /health - –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏",
                "confidence_metrics": "GET /confidence - –ø–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"
            }
        }
    
    @app.get("/confidence")
    async def get_confidence_metrics():
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
        try:
            log_file = "confidence_metrics.log"
            if os.path.exists(log_file):
                with open(log_file, "r", encoding="utf-8") as f:
                    lines = f.readlines()[-50:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 50 –∑–∞–ø–∏—Å–µ–π
                metrics = [json.loads(line) for line in lines]
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                if metrics:
                    confidences = [m.get("confidence", 0) for m in metrics]
                    avg_confidence = sum(confidences) / len(confidences)
                    
                    return {
                        "total_entries": len(metrics),
                        "average_confidence": avg_confidence,
                        "recent_entries": metrics[-10:],  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–ø–∏—Å–µ–π
                        "interpretation_distribution": {
                            "high": len([m for m in metrics if m.get("confidence", 0) > 0.8]),
                            "medium": len([m for m in metrics if 0.6 < m.get("confidence", 0) <= 0.8]),
                            "low": len([m for m in metrics if 0.3 < m.get("confidence", 0) <= 0.6]),
                            "very_low": len([m for m in metrics if m.get("confidence", 0) <= 0.3])
                        }
                    }
                return {"message": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –º–µ—Ç—Ä–∏–∫–∞—Ö"}
            return {"message": "–§–∞–π–ª –º–µ—Ç—Ä–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω"}
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {str(e)}")
    
    @app.post("/ask", response_model=Answer)
    async def ask(q: Question) -> Answer:
        """–û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤"""
        question = q.question.strip()
        
        if not question or len(question) < 3:
            raise HTTPException(
                status_code=400, 
                detail="–í–æ–ø—Ä–æ—Å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –≤–∞—à—É –ø—Ä–æ–±–ª–µ–º—É –ø–æ–¥—Ä–æ–±–Ω–µ–µ."
            )
        
        logger.info(f"–í–æ–ø—Ä–æ—Å –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞: {question}")
        
        # 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        priority = detect_priority(llm, question)
        logger.info(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority}")
        
        # 2. –†–∞—Å—à–∏—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å
        expanded_queries = expand_query(llm, question)
        
        # 3. –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        all_docs_with_scores = []
        
        for query in expanded_queries:
            try:
                docs_scores = vectordb.similarity_search_with_score(query, k=10)
                all_docs_with_scores.extend(docs_scores)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}': {e}")
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_docs = {}
        for doc, score in all_docs_with_scores:
            content_start = doc.page_content[:200]
            doc_hash = hash(content_start)
            if doc_hash not in unique_docs or score < unique_docs[doc_hash][1]:
                unique_docs[doc_hash] = (doc, score)
        
        sorted_docs = sorted(unique_docs.values(), key=lambda x: x[1])
        
        if not sorted_docs:
            logger.warning("–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π")
            return no_answer(priority, found_docs=False)
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(sorted_docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        
        # 4. –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context_parts = []
        used_docs = []
        
        for doc, score in sorted_docs:
            if score > 0.95:
                continue
            
            if not context_supports_question(doc.page_content, question, min_matches=1):
                continue
            
            context_parts.append(doc.page_content)
            used_docs.append((doc, score))
            
            if len('\n\n'.join(context_parts)) > 3500:
                break
            
            if len(context_parts) >= 5:
                break
        
        if not context_parts:
            logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            return no_answer(priority, found_docs=True)
        
        context = "\n\n".join(context_parts)
        logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {len(context_parts)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞")
        
        # 5. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        try:
            answer_chain = ANSWER_PROMPT | llm | StrOutputParser()
            answer_text = answer_chain.invoke({
                "context": context,
                "question": question
            }).strip()
            
            logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            answer_text = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É 900."
        
        # 6. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence, confidence_details = calculate_confidence(
            used_docs, question, answer_text, context
        )
        
        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        log_confidence_metrics(question, confidence, confidence_details)
        
        # 7. –û—Ü–µ–Ω–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç
        judge_result = judge_answer(
            llm=llm,
            question=question,
            answer=answer_text,
            context=context[:1500],
            priority=priority
        )
        
        helped = judge_result.get("helped", True)
        final_priority = judge_result.get("priority", priority.lower())
        
        # 8. –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å URL
        sources = format_sources(used_docs)
        
        # 9. –£–ª—É—á—à–∞–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ (–¥–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –∏ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é)
        final_answer = generate_enhanced_answer(
            answer_text, question, final_priority.upper(), helped, sources
        )
        
        # 10. –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è
        route_to = judge_result.get("route_to")
        
        if route_to:
            logger.info(f"–ü–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –Ω–∞ {route_to}")
        else:
            logger.info("–ê–≥–µ–Ω—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–ø—Ä–∞–≤–∏–ª—Å—è —Å –≤–æ–ø—Ä–æ—Å–æ–º")
        
        # 11. –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ª–æ–≥ (–¥–ª—è –∑–∞—â–∏—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞)
        logger.info(f"üìä –î–ï–¢–ê–õ–ò –£–í–ï–†–ï–ù–ù–û–°–¢–ò –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: '{question}'")
        logger.info(f"   –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {confidence:.2%}")
        logger.info(f"   –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: {confidence_details.get('interpretation', 'N/A')}")
        logger.info(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(used_docs)}")
        logger.info(f"   –°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {confidence_details.get('factors', {}).get('document_relevancy', {}).get('average', 0):.2%}")
        
        return Answer(
            answer=final_answer,
            sources=sources,
            priority=final_priority,
            route_to=route_to,
            judge_reason=judge_result.get("reason", "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞"),
            confidence=confidence,
            confidence_details=confidence_details
        )
    
    @app.get("/health")
    async def health_check():
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞"""
        try:
            test_response = llm.invoke("–ü—Ä–∏–≤–µ—Ç")
            return {
                "status": "healthy",
                "service": "SberBank Client Support AI",
                "llm": "available",
                "vectordb": "loaded",
                "features": [
                    "confidence_calculation",
                    "url_linking", 
                    "smart_routing",
                    "detailed_analytics"
                ],
                "message": "–°–µ—Ä–≤–∏—Å –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏"
            }
        except Exception as e:
            return {
                "status": "unhealthy",
                "service": "SberBank Client Support AI",
                "error": str(e),
                "llm": "unavailable",
                "message": "–¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama"
            }
    
    return app

app = create_app()
