import os
import re
import json
import logging
from typing import List, Optional, Dict, Tuple
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from datetime import datetime
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.chat_models import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from rag_config import VECTOR_DB_DIR

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# =====================
# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# =====================
CONFIDENCE_THRESHOLD = 0.4  # 70% –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏

# =====================
# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
# =====================
class Question(BaseModel):
    question: str

class Source(BaseModel):
    source: Optional[str] = None
    snippet: str
    relevance: Optional[float] = None
    url: Optional[str] = None
    document_type: Optional[str] = None

class Answer(BaseModel):
    answer: str
    sources: List[Source]
    priority: str  # low, medium, high
    route_to: Optional[str] = None  # L1 / L2 / L3
    judge_reason: str
    confidence: float = Field(..., ge=0.0, le=1.0)
    confidence_details: Optional[Dict] = None
    confidence_interpretation: Optional[str] = None
    confidence_below_threshold: bool = False  # –ù–æ–≤–æ–µ –ø–æ–ª–µ: —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞

# =====================
# –£—Ç–∏–ª–∏—Ç—ã –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
# =====================
STOP_WORDS = {
    "—á—Ç–æ", "–∫–∞–∫", "–∫–∞–∫–∏–µ", "–¥–ª—è", "—á–µ–≥–æ", "—ç—Ç–æ", "–ø—Ä–æ", "–æ",
    "–∏", "–∏–ª–∏", "–∞", "–≤", "–Ω–∞", "–ø–æ", "–∏–∑", "–ª–∏", "–∂–µ", "–Ω–µ",
    "–Ω–æ", "–∑–∞", "—É", "–æ—Ç", "–¥–æ", "–±–µ–∑", "–ø–æ–¥", "–Ω–∞–¥", "–ø—Ä–∏",
    "–∫", "—Å", "—Å–æ", "–≤–æ", "–æ–±", "—Ç–æ", "—Ç–∞–∫", "–≤–æ—Ç", "—Ç—É—Ç"
}

SBER_SITE_SECTIONS = {
    "–∫–∞—Ä—Ç–∞": "https://www.sberbank.ru/ru/person/bank_cards",
    "–≤–∫–ª–∞–¥": "https://www.sberbank.ru/ru/person/contributions",
    "–∫—Ä–µ–¥–∏—Ç": "https://www.sberbank.ru/ru/person/credits",
    "–∏–∏—Å": "https://www.sberbank.ru/ru/person/investments/iis",
    "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏": "https://www.sberbank.ru/ru/person/investments",
    "–∏–ø–æ—Ç–µ–∫–∞": "https://www.sberbank.ru/ru/person/credits/mortgage",
    "–ø–µ—Ä–µ–≤–æ–¥": "https://www.sberbank.ru/ru/person/transfer",
    "–ø–ª–∞—Ç–µ–∂": "https://www.sberbank.ru/ru/person/payments",
    "–æ–Ω–ª–∞–π–Ω": "https://www.sberbank.ru/ru/person/sberbankonline",
    "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ": "https://www.sberbank.ru/ru/person/sberbankonline/mobileapp",
    "–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ": "https://www.sberbank.ru/ru/person/sberbankonline/restore",
    "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å": "https://www.sberbank.ru/ru/person/security",
    "–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ": "https://www.sberbank.ru/ru/person/security/fraud",
    "–æ—Ç–¥–µ–ª–µ–Ω–∏–µ": "https://www.sberbank.ru/ru/person/branch",
    "–±–∞–Ω–∫–æ–º–∞—Ç": "https://www.sberbank.ru/ru/person/atm",
    "—Ç–∞—Ä–∏—Ñ": "https://www.sberbank.ru/ru/person/tariffs",
    "–∫–æ–º–∏—Å—Å–∏—è": "https://www.sberbank.ru/ru/person/tariffs",
    "faq": "https://www.sberbank.ru/ru/person/faq",
    "–ø–æ–¥–¥–µ—Ä–∂–∫–∞": "https://www.sberbank.ru/ru/person/help",
    "–∫–æ–Ω—Ç–∞–∫—Ç—ã": "https://www.sberbank.ru/ru/person/contacts",
}

HIGH_PRIORITY_TERMS = {
    "–¥–µ–Ω—å–≥–∏", "—Å—á–µ—Ç", "–∫–∞—Ä—Ç–∞", "–ø–µ—Ä–µ–≤–æ–¥", "–ø–ª–∞—Ç–µ–∂", "—Å–ø–∏—Å–∞–Ω–∏–µ", "–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ",
    "–≤–∑–ª–æ–º", "–∫—Ä–∞–∂–∞", "–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞", "–∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω", "–Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", "–æ—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞",
    "–ø–æ—Ç–µ—Ä—è–ª", "—É–∫—Ä–∞–ª–∏", "–Ω–µ—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π", "–∞—Ä–µ—Å—Ç", "–∞—Ä–µ—Å—Ç–æ–≤–∞–Ω", "–∫–æ–Ω—Ñ–∏—Å–∫–∞—Ü–∏—è",
    "–∞—Ä–µ—Å—Ç —Å—á–µ—Ç–∞", "–∑–∞–º–æ—Ä–æ–∂–µ–Ω", "—Å—Ä–æ—á–Ω–æ", "—ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ", "–∫—Ä–∏—Ç–∏—á–Ω–æ", "—É–≥—Ä–æ–∑–∞",
    "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "–ø–∞—Ä–æ–ª—å", "–≤—Ö–æ–¥", "–≤–∑–ª–æ–º–∞–ª–∏", "—Ñ–∏—à–∏–Ω–≥", "–æ–±–º–∞–Ω", "—Å–Ω—è–ª–∏",
    "–ø—Ä–æ–ø–∞–ª–∏", "–∏—Å—á–µ–∑–ª–∏", "—É–∫—Ä–∞–¥–µ–Ω", "—É–∫—Ä–∞–¥–µ–Ω–∞", "–∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞"
}

MEDIUM_PRIORITY_TERMS = {
    "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç", "–æ—à–∏–±–∫–∞", "—Å–±–æ–π", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã", "–Ω–µ –∑–∞—Ö–æ–¥–∏—Ç",
    "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "–æ–Ω–ª–∞–π–Ω", "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–±–∞–Ω–∫", "–º–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "—Å–∞–π—Ç",
    "–¥–æ—Å—Ç—É–ø", "–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è", "–≤—Ö–æ–¥", "–ª–æ–≥–∏–Ω", "–ø–∞—Ä–æ–ª—å", "–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
    "–∑–∞–±—ã–ª", "—É—Ç–µ—Ä—è", "—Å–º–µ–Ω–∞", "–Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞", "email", "–∫–æ–Ω—Ç–∞–∫—Ç—ã",
    "–Ω–∞—Å—Ç—Ä–æ–π–∫–∏", "–æ–ø–µ—Ä–∞—Ü–∏—è", "—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è", "–æ—Ç–∫–∞–∑", "–æ—Ç–∫–ª–æ–Ω–µ–Ω–æ", "–Ω–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç",
    "–Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è", "–∑–∞–≤–∏—Å–∞–µ—Ç", "—Ç–æ—Ä–º–æ–∑–∏—Ç", "–≥–ª—é—á–∏—Ç", "–±–∞–≥"
}

def extract_core_terms(text: str) -> set:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    words = re.findall(r"[a-z–∞-—è—ë0-9]+", text.lower())
    return {w for w in words if len(w) >= 3 and w not in STOP_WORDS}

def get_sber_site_url(question: str) -> Optional[str]:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ä–∞–∑–¥–µ–ª —Å–∞–π—Ç–∞ –°–±–µ—Ä–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞"""
    question_lower = question.lower()
    
    for keyword, url in SBER_SITE_SECTIONS.items():
        if keyword in question_lower:
            return url
    
    return None

def extract_urls_from_text(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    url_pattern = r'https?://(?:www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}\b[-a-zA-Z0-9()@:%_\+.~#?&//=]*'
    urls = re.findall(url_pattern, text)
    return urls

def generate_document_url(source_path: str, content: str) -> Optional[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–ª–∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç URL –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    if not source_path:
        return None
    
    filename = os.path.basename(source_path).lower()
    
    urls_in_content = extract_urls_from_text(content[:1000])
    if urls_in_content:
        sber_urls = [url for url in urls_in_content if 'sberbank' in url]
        if sber_urls:
            return sber_urls[0]
    
    if source_path.endswith('.html'):
        html_name = os.path.splitext(filename)[0]
        for keyword, url in SBER_SITE_SECTIONS.items():
            if keyword in html_name:
                return url
    
    return None

def is_valid_sber_url(url: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL –¥–æ–ø—É—Å—Ç–∏–º—ã–º URL –°–±–µ—Ä–∞"""
    if not url:
        return False
    
    valid_domains = ['sberbank.ru', 'sberbank.com', 'sber.ru']
    return any(domain in url for domain in valid_domains)

def context_supports_question(context: str, question: str, min_matches: int = 2) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –≤–æ–ø—Ä–æ—Å–∞"""
    context_lower = context.lower()
    terms = extract_core_terms(question)
    
    if not terms:
        return True
    
    matches = sum(1 for term in terms if term in context_lower)
    return matches >= min_matches

def get_relevancy_interpretation(score: float) -> str:
    """–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    if score >= 0.9:
        return "–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"
    elif score >= 0.8:
        return "–í—ã—Å–æ–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"
    elif score >= 0.7:
        return "–•–æ—Ä–æ—à–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"
    elif score >= 0.6:
        return "–°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"
    elif score >= 0.5:
        return "–£–º–µ—Ä–µ–Ω–Ω–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"
    else:
        return "–ù–∏–∑–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"

def analyze_answer_quality(answer: str, question: str) -> Dict:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞ - –º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥–∏–π –∫ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏"""
    answer_lower = answer.lower()
    question_lower = question.lower()
    
    scores = {}
    
    # 1. –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ (–±–æ–ª–µ–µ –≥–∏–±–∫–∞—è)
    ideal_min_length = 30
    ideal_max_length = 500
    
    if len(answer) < ideal_min_length:
        length_score = len(answer) / ideal_min_length
    elif len(answer) > ideal_max_length:
        length_score = 1.0  # –î–ª–∏–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã - —ç—Ç–æ —Ö–æ—Ä–æ—à–æ
    else:
        length_score = 0.7 + (len(answer) - ideal_min_length) / (ideal_max_length - ideal_min_length) * 0.3
    
    length_score = max(0.3, min(1.0, length_score))
    scores["length"] = {
        "score": length_score,
        "length": len(answer),
        "ideal_range": f"{ideal_min_length}-{ideal_max_length}"
    }
    
    # 2. –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ñ—Ä–∞–∑ (—Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä)
    negative_phrases = [
        "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç", "–Ω–µ –∑–Ω–∞—é", "–Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å", 
        "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö", "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ",
        "–∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –º–æ–≥—É", "–Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏",
        "–∏–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ", "—è –Ω–µ –Ω–∞—à–µ–ª"
    ]
    
    has_negative = any(phrase in answer_lower for phrase in negative_phrases)
    negative_score = 0.0 if has_negative else 1.0
    scores["negatives"] = {
        "score": negative_score,
        "has_negative": has_negative
    }
    
    # 3. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞
    structure_patterns = [
        r'\d+\.\s',  # –ù—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
        r'[-‚Ä¢*]\s',  # –ú–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
        r'[–ü–ø]–µ—Ä–≤—ã–π|[–í–≤]—Ç–æ—Ä–æ–π|[–¢—Ç]—Ä–µ—Ç–∏–π',  # –ü–æ—Ä—è–¥–∫–æ–≤—ã–µ –Ω–æ–º–µ—Ä–∞
    ]
    
    structure_matches = sum(1 for pattern in structure_patterns 
                           if re.search(pattern, answer))
    structure_score = min(structure_matches / 2, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 2 –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
    scores["structure"] = {
        "score": structure_score,
        "matches": structure_matches
    }
    
    # 4. –ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ—Å—Ç—å (–º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥–∞—è)
    if re.search(r'\d+', answer):  # –ï—Å—Ç—å —Ö–æ—Ç—å –∫–∞–∫–∏–µ-—Ç–æ —Ü–∏—Ñ—Ä—ã
        specificity_score = 0.8
    elif any(word in answer_lower for word in ['—Å–±–µ—Ä–±–∞–Ω–∫', '–∫–∞—Ä—Ç–∞', '—Å—á–µ—Ç', '–ø–∞—Ä–æ–ª—å']):
        specificity_score = 0.7
    else:
        specificity_score = 0.5
    
    scores["specificity"] = {
        "score": specificity_score
    }
    
    # –ò—Ç–æ–≥–æ–≤—ã–π —Å—á–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ (–≤–µ—Å–∞)
    weights = {
        "length": 0.15,
        "negatives": 0.50,  # –°–∞–º—ã–π –≤–∞–∂–Ω—ã–π - –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ "–Ω–µ –∑–Ω–∞—é"
        "structure": 0.20,
        "specificity": 0.15
    }
    
    total_score = sum(scores[key]["score"] * weights[key] for key in weights)
    scores["total_score"] = total_score
    scores["weights"] = weights
    
    return scores

def calculate_qa_similarity(question: str, answer: str) -> float:
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é —Å—Ö–æ–∂–µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å–∞ –∏ –æ—Ç–≤–µ—Ç–∞"""
    stop_words = STOP_WORDS.union({
        '–≤–∞—Å', '–≤–∞–º', '–≤–∞—à', '–Ω–∞—à', '—Å–≤–æ–π', '—Å–≤–æ–∏', '—Å–≤–æ–µ–π',
        '—ç—Ç–æ—Ç', '—ç—Ç–∞', '—ç—Ç–æ', '—ç—Ç–∏', '—Ç–∞–∫–æ–π', '—Ç–∞–∫–∞—è', '—Ç–∞–∫–æ–µ'
    })
    
    question_terms = set(
        word.lower() for word in re.findall(r'\b\w{3,}\b', question)
        if word.lower() not in stop_words
    )
    
    answer_terms = set(
        word.lower() for word in re.findall(r'\b\w{3,}\b', answer)
        if word.lower() not in stop_words
    )
    
    if not question_terms or not answer_terms:
        return 0.3
    
    intersection = len(question_terms.intersection(answer_terms))
    union = len(question_terms.union(answer_terms))
    
    if union == 0:
        return 0.0
    
    similarity = intersection / union
    
    important_terms = {'—Å–±–µ—Ä–±–∞–Ω–∫', '–∫–∞—Ä—Ç–∞', '—Å—á–µ—Ç', '–¥–µ–Ω—å–≥–∏', '–ø–µ—Ä–µ–≤–æ–¥', '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'}
    important_matches = len(important_terms.intersection(question_terms.intersection(answer_terms)))
    
    similarity += important_matches * 0.1
    return min(similarity, 1.0)

def calculate_confidence(
    docs_with_scores: List[Tuple],
    question: str,
    answer: str,
    context: str,
    priority: str
) -> Tuple[float, Dict, str]:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ - –±–µ–∑ —Å—Ç—Ä–æ–≥–æ–≥–æ Q/A similarity
    
    –ù–æ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã:
    1. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –ª—É—á—à–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (30%)
    2. –°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ç–æ–ø-3 (20%)
    3. –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞ (35%) ‚Üê –£–í–ï–õ–ò–ß–ï–ù–û
    4. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ—Ç–≤–µ—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (15%) ‚Üê –í–ú–ï–°–¢–û Q/A similarity
    """
    details = {
        "calculation_time": datetime.now().isoformat(),
        "factors": {},
        "question_preview": question[:100],
        "answer_length": len(answer),
        "calculation_method": "v3_context_alignment"
    }
    
    if not docs_with_scores:
        details["factors"]["no_documents"] = "–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        interpretation = "–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–Ω–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)"
        details["interpretation"] = interpretation
        return 0.1, details, interpretation
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    relevancy_scores = [1.0 - score for _, score in docs_with_scores]
    
    # –§–∞–∫—Ç–æ—Ä 1: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –õ–£–ß–®–ï–ì–û –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–≤–µ—Å 30%)
    best_relevancy = max(relevancy_scores) if relevancy_scores else 0
    details["factors"]["best_document_relevancy"] = {
        "score": best_relevancy,
        "interpretation": get_relevancy_interpretation(best_relevancy)
    }
    relevancy_factor = best_relevancy * 0.3
    
    # –§–∞–∫—Ç–æ—Ä 2: –°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¢–û–ü-3 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–≤–µ—Å 20%)
    top_n = min(3, len(relevancy_scores))
    top_relevancy_scores = sorted(relevancy_scores, reverse=True)[:top_n]
    avg_top_relevancy = sum(top_relevancy_scores) / len(top_relevancy_scores)
    details["factors"]["top_documents_relevancy"] = {
        "average": avg_top_relevancy,
        "scores": top_relevancy_scores,
        "count": top_n
    }
    top_relevancy_factor = avg_top_relevancy * 0.2
    
    # –§–∞–∫—Ç–æ—Ä 3: –ö–∞—á–µ—Å—Ç–≤–æ –∏ –ø–æ–ª–Ω–æ—Ç–∞ –æ—Ç–≤–µ—Ç–∞ (–≤–µ—Å 35%) ‚Üê –£–í–ï–õ–ò–ß–ï–ù–û
    answer_quality_score = analyze_answer_quality(answer, question)
    details["factors"]["answer_quality"] = answer_quality_score
    quality_factor = answer_quality_score["total_score"] * 0.35
    
    # –§–∞–∫—Ç–æ—Ä 4: –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ—Ç–≤–µ—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (–≤–µ—Å 15%) ‚Üê –ù–û–í–´–ô –í–ú–ï–°–¢–û Q/A similarity
    context_alignment = calculate_context_alignment(answer, context)
    details["factors"]["context_alignment"] = {
        "score": context_alignment,
        "method": "answer_terms_in_context"
    }
    alignment_factor = context_alignment * 0.15
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    confidence_score = (
        relevancy_factor + 
        top_relevancy_factor + 
        quality_factor + 
        alignment_factor
    )
    
    # –ë–û–ù–£–°: –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤ –æ—Ç–≤–µ—Ç–µ
    if has_concrete_instructions(answer):
        confidence_score = min(confidence_score + 0.1, 1.0)
        details["factors"]["concrete_instructions_bonus"] = 0.1
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –∏ –æ–∫—Ä—É–≥–ª—è–µ–º
    confidence_score = max(0.0, min(1.0, confidence_score))
    confidence_score = round(confidence_score, 3)
    
    # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
    interpretation = get_confidence_interpretation(confidence_score, priority)
    details["interpretation"] = interpretation
    details["final_score"] = confidence_score
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∞–∫—Ç–æ—Ä—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    logger.info(f"üìä –£–í–ï–†–ï–ù–ù–û–°–¢–¨ v3:")
    logger.info(f"   –õ—É—á—à–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {best_relevancy:.2%}")
    logger.info(f"   –°—Ä–µ–¥–Ω—è—è —Ç–æ–ø-3: {avg_top_relevancy:.2%}")
    logger.info(f"   –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞: {answer_quality_score['total_score']:.2%}")
    logger.info(f"   –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É: {context_alignment:.2%}")
    logger.info(f"   –ò–¢–û–ì–û: {confidence_score:.2%}")
    
    return confidence_score, details, interpretation


def calculate_context_alignment(answer: str, context: str) -> float:
    """
    –ù–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –æ—Ç–≤–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
    """
    if not answer or not context:
        return 0.5
    
    answer_lower = answer.lower()
    context_lower = context.lower()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞ (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞)
    answer_terms = set(
        word for word in re.findall(r'\b\w{3,}\b', answer_lower)
        if word not in STOP_WORDS
    )
    
    if not answer_terms:
        return 0.5
    
    # –°–∫–æ–ª—å–∫–æ —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–∑ –æ—Ç–≤–µ—Ç–∞ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
    context_terms = set(
        word for word in re.findall(r'\b\w{3,}\b', context_lower[:2000])
        if word not in STOP_WORDS
    )
    
    matches = len(answer_terms.intersection(context_terms))
    alignment = matches / len(answer_terms)
    
    # –ë–æ–Ω—É—Å—ã –∑–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
    bonuses = 0.0
    
    # 1. –ë–æ–Ω—É—Å –∑–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–æ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
    instruction_words = {'—à–∞–≥', '–¥–µ–π—Å—Ç–≤–∏–µ', '–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ', '–Ω—É–∂–Ω–æ', '—Ç—Ä–µ–±—É–µ—Ç—Å—è', 
                        '–º–æ–∂–Ω–æ', '—Å–ª–µ–¥—É–µ—Ç', '—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è', '—Å–æ–≤–µ—Ç—É–µ–º'}
    if any(word in answer_lower for word in instruction_words):
        bonuses += 0.15
    
    # 2. –ë–æ–Ω—É—Å –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–Ω–æ–º–µ—Ä–∞, —Ç–µ–ª–µ—Ñ–æ–Ω—ã, —Å—É–º–º—ã)
    if re.search(r'\d+', answer):
        bonuses += 0.10
    
    # 3. –ë–æ–Ω—É—Å –∑–∞ —Å—Å—ã–ª–∫–∏ –∏–ª–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Å–∞–π—Ç–∞
    if 'sberbank.ru' in answer_lower or 'https://' in answer_lower:
        bonuses += 0.10
    
    alignment = min(alignment + bonuses, 1.0)
    
    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å
    return min(max(alignment, 0.4), 1.0)  # –ú–∏–Ω–∏–º—É–º 40%


def has_concrete_instructions(answer: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ—Ç–≤–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"""
    answer_lower = answer.lower()
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
    patterns = [
        r'\d+\.\s',  # –ù—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
        r'[-‚Ä¢*]\s',  # –ú–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
        r'—à–∞–≥\s+\d+',  # –®–∞–≥ 1, –®–∞–≥ 2
        r'—Å–Ω–∞—á–∞–ª–∞\s+', r'–∑–∞—Ç–µ–º\s+', r'–ø–æ—Å–ª–µ\s+',  # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        r'–Ω–∞–∂–º–∏—Ç–µ\s+', r'–≤—ã–±–µ—Ä–∏—Ç–µ\s+', r'–≤–≤–µ–¥–∏—Ç–µ\s+',  # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
    ]
    
    return any(re.search(pattern, answer_lower) for pattern in patterns)


def get_confidence_interpretation(score: float, priority: str) -> str:
    """–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
    if score >= 0.85:
        base = "–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
    elif score >= 0.70:
        base = "–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
    elif score >= 0.55:
        base = "–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
    elif score >= 0.40:
        base = "–£–º–µ—Ä–µ–Ω–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
    elif score >= 0.25:
        base = "–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
    else:
        base = "–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
    
    if priority == "high" and score > 0.7:
        return f"{base} (—Å —É—á–µ—Ç–æ–º –≤–∞–∂–Ω–æ—Å—Ç–∏ –≤–æ–ø—Ä–æ—Å–∞)"
    
    return base

def get_question_priority_keywords(question: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
    q_lower = question.lower()
    
    if any(term in q_lower for term in HIGH_PRIORITY_TERMS):
        return "high"
    
    if any(term in q_lower for term in MEDIUM_PRIORITY_TERMS):
        return "medium"
    
    return "low"

def needs_immediate_escalation(confidence: float, priority: str) -> Tuple[bool, str]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ª–∏ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è —ç—Å–∫–∞–ª–∞—Ü–∏—è
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - –Ω—É–∂–Ω–æ_–ª–∏_—ç—Å–∫–∞–ª–∏—Ä–æ–≤–∞—Ç—å (bool)
    - –ø—Ä–∏—á–∏–Ω–∞ (str)
    """
    # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞
    if confidence < CONFIDENCE_THRESHOLD:
        if priority == "high":
            return True, f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.1%} –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞ {CONFIDENCE_THRESHOLD:.0%} –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–µ –≤–æ–ø—Ä–æ—Å–∞"
        elif priority == "medium":
            return True, f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.1%} –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞ {CONFIDENCE_THRESHOLD:.0%}"
        else:
            # –î–ª—è low –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ –≤—Å–µ —Ä–∞–≤–Ω–æ —ç—Å–∫–∞–ª–∏—Ä—É–µ–º, –Ω–æ –Ω–∞ L1
            return True, f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.1%} –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞ {CONFIDENCE_THRESHOLD:.0%}"
    
    return False, ""

def get_escalation_level(priority: str, confidence: float) -> Tuple[str, str]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —ç—Å–∫–∞–ª–∞—Ü–∏–∏
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - —É—Ä–æ–≤–µ–Ω—å (L1/L2/L3)
    - –ø—Ä–∏—á–∏–Ω–∞
    """
    # –î–ª—è HIGH –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ - –≤—Å–µ–≥–¥–∞ L3, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    if priority == "high":
        if confidence < CONFIDENCE_THRESHOLD:
            return "L3", f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Å —Ñ–∏–Ω–∞–Ω—Å–∞–º–∏/–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é. –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.1%} < {CONFIDENCE_THRESHOLD:.0%}"
        else:
            return "L3", "–í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤–æ–ø—Ä–æ—Å–∞ (—Ñ–∏–Ω–∞–Ω—Å—ã/–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å) —Ç—Ä–µ–±—É–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ L3"
    
    # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ - –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    if confidence < CONFIDENCE_THRESHOLD:
        if priority == "medium":
            return "L2", f"–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Ç—Ä–µ–±—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞. –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.1%} < {CONFIDENCE_THRESHOLD:.0%}"
        else:  # low
            return "L1", f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è. –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.1%} < {CONFIDENCE_THRESHOLD:.0%}"
    
    # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ –∏ –Ω–µ HIGH - –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞
    return None, ""


def generate_low_confidence_response(priority: str, confidence: float, reason: str) -> Tuple[str, str]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –ø—Ä–∏ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - –æ—Ç–≤–µ—Ç –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞
    - —É—Ä–æ–≤–µ–Ω—å –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏
    """
    if priority == "high":
        answer = (
            f"üî¥ **–°–†–û–ß–ù–û! –í–ê–® –í–û–ü–†–û–° –ü–ï–†–ï–î–ê–ù –°–ü–ï–¶–ò–ê–õ–ò–°–¢–ê–ú –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò (L3)**\n\n"
            f"–í–∞—à –≤–æ–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤ –ø–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.\n\n"
            f"**–ù–ï–ú–ï–î–õ–ï–ù–ù–´–ï –î–ï–ô–°–¢–í–ò–Ø:**\n"
            f"1. üìû **–ü–æ–∑–≤–æ–Ω–∏—Ç–µ –≤ —Å–ª—É–∂–±—É –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –°–±–µ—Ä–±–∞–Ω–∫–∞: 900** (—Å –º–æ–±–∏–ª—å–Ω–æ–≥–æ) –∏–ª–∏ **+7 (495) 500-55-50**\n"
            f"2. üö´ **–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –∑–∞–±–ª–æ–∫–∏—Ä—É–π—Ç–µ –∫–∞—Ä—Ç—É** —á–µ—Ä–µ–∑ –º–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –°–±–µ—Ä–ë–∞–Ω–∫ –û–Ω–ª–∞–π–Ω\n"
            f"3. üè¶ **–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –±–ª–∏–∂–∞–π—à–µ–µ –æ—Ç–¥–µ–ª–µ–Ω–∏–µ** —Å –ø–∞—Å–ø–æ—Ä—Ç–æ–º\n\n"
            f"**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—Ä–∞—â–µ–Ω–∏–∏:**\n"
            f"‚Ä¢ –£—Ä–æ–≤–µ–Ω—å –æ–±—Ä–∞–±–æ—Ç–∫–∏: **L3 (—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)**\n"
            f"‚Ä¢ –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: **–≤ —Ç–µ—á–µ–Ω–∏–µ 15 –º–∏–Ω—É—Ç**\n"
            f"‚Ä¢ –¢–µ–ª–µ—Ñ–æ–Ω –¥–ª—è —Å—Ä–æ—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤: **900**\n\n"
            f"*–ü—Ä–∏—á–∏–Ω–∞ —ç—Å–∫–∞–ª–∞—Ü–∏–∏: {reason}*"
        )
        return answer, "L3"
    
    elif priority == "medium":
        answer = (
            f"üîÑ **–í–ê–® –í–û–ü–†–û–° –ü–ï–†–ï–î–ê–ù –¢–ï–•–ù–ò–ß–ï–°–ö–û–ú–£ –°–ü–ï–¶–ò–ê–õ–ò–°–¢–£ (L2)**\n\n"
            f"–î–ª—è —Ä–µ—à–µ–Ω–∏—è –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–º–æ—â—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞.\n\n"
            f"**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:**\n"
            f"1. üìû **–ü–æ–∑–≤–æ–Ω–∏—Ç–µ –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É: 900**\n"
            f"2. üåê –ü–æ—Å–µ—Ç–∏—Ç–µ —Å–∞–π—Ç: www.sberbank.ru\n"
            f"3. üì± –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ\n\n"
            f"**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—Ä–∞—â–µ–Ω–∏–∏:**\n"
            f"‚Ä¢ –£—Ä–æ–≤–µ–Ω—å –æ–±—Ä–∞–±–æ—Ç–∫–∏: **L2 (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã)**\n"
            f"‚Ä¢ –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: **–≤ —Ç–µ—á–µ–Ω–∏–µ 2 —á–∞—Å–æ–≤**\n"
            f"‚Ä¢ –¢–µ–ª–µ—Ñ–æ–Ω –ø–æ–¥–¥–µ—Ä–∂–∫–∏: **900**\n\n"
            f"*–ü—Ä–∏—á–∏–Ω–∞ —ç—Å–∫–∞–ª–∞—Ü–∏–∏: {reason}*"
        )
        return answer, "L2"
    
    else:
        answer = (
            f"‚ÑπÔ∏è **–í–ê–® –í–û–ü–†–û–° –ü–ï–†–ï–î–ê–ù –ö–û–ù–°–£–õ–¨–¢–ê–ù–¢–£ (L1)**\n\n"
            f"–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤–∞—à –≤–æ–ø—Ä–æ—Å –ø–µ—Ä–µ–¥–∞–Ω –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—É.\n\n"
            f"**–í—ã –º–æ–∂–µ—Ç–µ:**\n"
            f"1. üìû **–ü–æ–∑–≤–æ–Ω–∏—Ç—å –≤ —Å–ø—Ä–∞–≤–æ—á–Ω—É—é —Å–ª—É–∂–±—É: 900**\n"
            f"2. üåê –ù–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ —Å–∞–π—Ç–µ: www.sberbank.ru\n"
            f"3. üè¶ –û–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ –æ—Ç–¥–µ–ª–µ–Ω–∏–µ –±–∞–Ω–∫–∞\n\n"
            f"**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—Ä–∞—â–µ–Ω–∏–∏:**\n"
            f"‚Ä¢ –£—Ä–æ–≤–µ–Ω—å –æ–±—Ä–∞–±–æ—Ç–∫–∏: **L1 (–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—ã)**\n"
            f"‚Ä¢ –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: **–≤ —Ç–µ—á–µ–Ω–∏–µ 4 —á–∞—Å–æ–≤**\n"
            f"‚Ä¢ –¢–µ–ª–µ—Ñ–æ–Ω —Å–ø—Ä–∞–≤–æ—á–Ω–æ–π: **900**\n\n"
            f"*–ü—Ä–∏—á–∏–Ω–∞ —ç—Å–∫–∞–ª–∞—Ü–∏–∏: {reason}*"
        )
        return answer, "L1"

# =====================
# –ü—Ä–æ–º–ø—Ç—ã
# =====================
PRIORITY_PROMPT = ChatPromptTemplate.from_messages([
    (
        "system",
        """–¢—ã ‚Äî —Å–∏—Å—Ç–µ–º–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–±—Ä–∞—â–µ–Ω–∏–π –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ —Å–ª—É–∂–±—É –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –°–±–µ—Ä–±–∞–Ω–∫–∞.
–û–ø—Ä–µ–¥–µ–ª–∏ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å –≤–æ–ø—Ä–æ—Å–∞ –ö–õ–ò–ï–ù–¢–ê.

HIGH (–≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) ‚Äî –≤—Å—ë, —á—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å –¥–µ–Ω—å–≥–∞–º–∏, —Å—á–µ—Ç–∞–º–∏, –∫–∞—Ä—Ç–∞–º–∏, –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏, –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ–º, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é, –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞–º–∏, —Å—Ä–æ—á–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏, –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–º–∏/—É–∫—Ä–∞–¥–µ–Ω–Ω—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏, –Ω–µ—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–ø–∏—Å–∞–Ω–∏—è–º–∏.

MEDIUM (—Å—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) ‚Äî —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã: –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, —Å–∞–π—Ç, –æ—à–∏–±–∫–∏ –≤—Ö–æ–¥–∞, –ø—Ä–æ–±–ª–µ–º—ã —Å –¥–æ—Å—Ç—É–ø–æ–º, —Å–±–æ–∏ –≤ —Ä–∞–±–æ—Ç–µ —Å–µ—Ä–≤–∏—Å–æ–≤, –≤–æ–ø—Ä–æ—Å—ã –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º, –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–∞.

LOW (–Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) ‚Äî –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã: —Å–ø—Ä–∞–≤–∫–∞, –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã, –∞–¥—Ä–µ—Å–∞ –æ—Ç–¥–µ–ª–µ–Ω–∏–π, —Ç–∞—Ä–∏—Ñ—ã, —É—Å–ª–æ–≤–∏—è —É—Å–ª—É–≥, –æ–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã.

–û—Ç–≤–µ—Ç—å –û–î–ù–ò–ú —Å–ª–æ–≤–æ–º: LOW, MEDIUM –∏–ª–∏ HIGH."""
    ),
    ("human", "–í–û–ü–†–û–° –ö–õ–ò–ï–ù–¢–ê: {question}")
])

JUDGE_PROMPT = ChatPromptTemplate.from_messages([
    (
        "system",
        """–¢—ã ‚Äî AI-—Å—É–¥—å—è —Å–ª—É–∂–±—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –°–±–µ—Ä–±–∞–Ω–∫–∞ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å:
1. –ù–∞—Å–∫–æ–ª—å–∫–æ –ø–æ–ª–Ω–æ –∏ –ø–æ–ª–µ–∑–Ω–æ –æ—Ç–≤–µ—Ç–∏–ª –∞–≥–µ–Ω—Ç
2. –ù—É–∂–Ω–∞ –ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–º–æ—â—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –ü–û–°–õ–ï –æ—Ç–≤–µ—Ç–∞ –∞–≥–µ–Ω—Ç–∞

–í–µ—Ä–Ω–∏ –°–¢–†–û–ì–û JSON:

{
  "helped": true | false,
  "priority": "low" | "medium" | "high",
  "route_to": "L1" | "L2" | "L3" | null,
  "reason": "–∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º"
}

–í–∞–∂–Ω–æ: route_to = null –µ—Å–ª–∏ –∞–≥–µ–Ω—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ—à–∏–ª –≤–æ–ø—Ä–æ—Å.
route_to != null –µ—Å–ª–∏ –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ –∞–≥–µ–Ω—Ç–∞ –Ω—É–∂–Ω—ã –¥–µ–π—Å—Ç–≤–∏—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞."""
    ),
    (
        "human",
        """–í–û–ü–†–û–° –ö–õ–ò–ï–ù–¢–ê:
{question}

–û–¢–í–ï–¢ –ê–ì–ï–ù–¢–ê:
{answer}

–ö–û–ù–¢–ï–ö–°–¢ (–Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –æ—Ç–≤–µ—á–∞–ª –∞–≥–µ–Ω—Ç):
{context}"""
    )
])

ANSWER_PROMPT = ChatPromptTemplate.from_messages([
    (
        "system",
        """–¢—ã ‚Äî AI-–∞–≥–µ–Ω—Ç –ø–µ—Ä–≤–æ–π –ª–∏–Ω–∏–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –°–±–µ—Ä–±–∞–Ω–∫–∞.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ–≥–∞—Ç—å –∫–ª–∏–µ–Ω—Ç–∞–º —Ä–µ—à–∞—Ç—å –∏—Ö –≤–æ–ø—Ä–æ—Å—ã, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.

–í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
1. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
2. –î–∞–π –ø—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π
3. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã ‚Äî –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –ø–æ—à–∞–≥–æ–≤—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é
4. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å URL –Ω–∞ —Å–∞–π—Ç –°–±–µ—Ä–∞ - –≤–∫–ª—é—á–∏ –∏—Ö –≤ –æ—Ç–≤–µ—Ç
5. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ —á—Ç–æ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É
6. –ù–ò–ö–û–ì–î–ê –Ω–µ —Å–ø—Ä–∞—à–∏–≤–∞–π "–ø–æ–º–æ–≥ –ª–∏ –æ—Ç–≤–µ—Ç" –∏–ª–∏ "–ø–æ–Ω—è—Ç–Ω–æ –ª–∏ –æ–±—ä—è—Å–Ω–∏–ª"

–°–¢–ò–õ–¨ –û–ë–©–ï–ù–ò–Ø:
- –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –±–µ–∑ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–µ–π
- –¢–æ–ª—å–∫–æ –ø–æ –¥–µ–ª—É
- –ß–µ—Ç–∫–æ, –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ, —Å –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —à–∞–≥–∞–º–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
- –ë–µ–∑ —ç–º–ø–∞—Ç–∏–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤ (–≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –∫—Ä–∏—Ç–∏—á–Ω–æ)

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
- –ü—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å
- –ï—Å–ª–∏ –Ω—É–∂–Ω—ã –¥–µ–π—Å—Ç–≤–∏—è: 1. –°–¥–µ–ª–∞–π —ç—Ç–æ. 2. –ó–∞—Ç–µ–º —ç—Ç–æ. 3. –ü—Ä–æ–≤–µ—Ä—å —Ç–æ.
- –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É: "–î–ª—è —Ä–µ—à–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏. –û–±—Ä–∞—â–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ."
"""
    ),
    (
        "human",
        """–ë–ê–ó–ê –ó–ù–ê–ù–ò–ô –í–ù–£–¢–†–ï–ù–ù–ò–• –°–ï–†–í–ò–°–û–í:
{context}

–í–û–ü–†–û–° –°–û–¢–†–£–î–ù–ò–ö–ê:
{question}

–¢–í–û–ô –û–¢–í–ï–¢:"""
    )
])

EXPANSION_PROMPT = ChatPromptTemplate.from_messages([
    (
        "system",
        """–ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞ 2-3 —Å–ø–æ—Å–æ–±–∞–º–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.
–°–æ—Ö—Ä–∞–Ω–∏ –æ—Å–Ω–æ–≤–Ω–æ–π —Å–º—ã—Å–ª, –Ω–µ –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—ã–µ —Ñ–∞–∫—Ç—ã.
–ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Å—Ç—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏."""
    ),
    ("human", "–í–û–ü–†–û–° –ö–õ–ò–ï–ù–¢–ê: {question}")
])

# =====================
# –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# =====================
def detect_priority(llm, question: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤–æ–ø—Ä–æ—Å–∞ –∫–ª–∏–µ–Ω—Ç–∞"""
    try:
        result = (PRIORITY_PROMPT | llm | StrOutputParser()).invoke(
            {"question": question}
        )
        result = result.strip().upper()
        if result in {"LOW", "MEDIUM", "HIGH"}:
            logger.info(f"LLM –æ–ø—Ä–µ–¥–µ–ª–∏–ª –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {result}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ—Ä–∞–∑
            question_lower = question.lower()
            critical_phrases = [
                "—É–∫—Ä–∞–ª–∏", "–ø–æ—Ç–µ—Ä—è–ª", "–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ", "–≤–∑–ª–æ–º", "–∫—Ä–∞–∂–∞", 
                "—Å–ø–∏—Å–∞–ª–∏", "–Ω–µ—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω", "–ø—Ä–æ–ø–∞–ª–∏ –¥–µ–Ω—å–≥–∏", "—É–∫—Ä–∞–¥–µ–Ω",
                "–∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞", "–∞—Ä–µ—Å—Ç", "–∫–æ–Ω—Ñ–∏—Å–∫–∞—Ü–∏—è"
            ]
            
            if any(phrase in question_lower for phrase in critical_phrases):
                logger.info(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è —Ñ—Ä–∞–∑–∞, –ø–æ–≤—ã—à–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–æ HIGH")
                return "HIGH"
            
            return result
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ LLM: {e}")
    
    priority = get_question_priority_keywords(question).upper()
    logger.info(f"Keyword –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority}")
    return priority

def judge_answer(llm, question: str, answer: str, context: str, priority: str) -> dict:
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç: –ø–æ–º–æ–≥ –ª–∏ –∞–≥–µ–Ω—Ç –∏ –Ω—É–∂–µ–Ω –ª–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –ü–û–°–õ–ï –æ—Ç–≤–µ—Ç–∞"""
    parser = JsonOutputParser()
    chain = JUDGE_PROMPT | llm | parser
    
    try:
        result = chain.invoke({
            "question": question,
            "answer": answer,
            "context": context[:2000]
        })
        
        if not isinstance(result, dict):
            result = {}
        
        answer_lower = answer.lower()
        if "helped" not in result:
            not_helpful_phrases = [
                "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç", "–Ω–µ –∑–Ω–∞—é", "–Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å", 
                "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö", "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
            ]
            result["helped"] = not any(phrase in answer_lower for phrase in not_helpful_phrases)
        
        if "priority" not in result:
            result["priority"] = priority.lower()
        
        if "route_to" not in result:
            if not result.get("helped", True):
                if result["priority"] == "high":
                    result["route_to"] = "L3"
                elif result["priority"] == "medium":
                    result["route_to"] = "L2"
                else:
                    result["route_to"] = "L1"
            else:
                needs_human = (
                    result["priority"] == "high" and 
                    any(word in answer_lower for word in ["–ø–æ–∑–≤–æ–Ω–∏—Ç–µ", "–æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å", "—Å–æ—Ç—Ä—É–¥–Ω–∏–∫"])
                ) or (
                    result["priority"] == "medium" and
                    any(word in answer_lower for word in ["–ø–æ–∑–≤–æ–Ω–∏—Ç–µ –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É", "–æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –æ–ø–µ—Ä–∞—Ç–æ—Ä—É"])
                )
                
                if needs_human:
                    result["route_to"] = "L3" if result["priority"] == "high" else "L2"
                else:
                    result["route_to"] = None
        
        if "reason" not in result:
            if result.get("helped", True):
                if result.get("route_to"):
                    result["reason"] = "–ê–≥–µ–Ω—Ç –¥–∞–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –Ω–æ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π –Ω—É–∂–µ–Ω —Å–æ—Ç—Ä—É–¥–Ω–∏–∫"
                else:
                    result["reason"] = "–ê–≥–µ–Ω—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–≤–µ—Ç–∏–ª –Ω–∞ –≤–æ–ø—Ä–æ—Å"
            else:
                result["reason"] = "–ê–≥–µ–Ω—Ç –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞"
        
        return result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –æ—Ç–≤–µ—Ç–∞: {e}")
        return {
            "helped": True,
            "priority": priority.lower(),
            "route_to": "L2" if priority == "HIGH" else None,
            "reason": "–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –∞–≥–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∏–ª"
        }

def expand_query(llm, question: str) -> List[str]:
    """–†–∞—Å—à–∏—Ä—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞"""
    expansions = [question]
    
    try:
        expansions_raw = (EXPANSION_PROMPT | llm | StrOutputParser()).invoke(
            {"question": question}
        )
        
        for line in expansions_raw.split('\n'):
            line = line.strip()
            if line and len(line) > 10:
                clean_line = re.sub(r'^[\d\-‚Ä¢\.\)\s]+', '', line)
                if clean_line and clean_line != question:
                    expansions.append(clean_line)
        
        expansions = list(dict.fromkeys(expansions))[:4]
        
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
    
    return expansions

def format_sources(docs_with_scores, max_sources: int = 3) -> List[Source]:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –∫–ª–∏–µ–Ω—Ç—É —Å URL"""
    sources = []
    
    for doc, score in docs_with_scores[:max_sources]:
        snippet = doc.page_content[:300].strip()
        if len(doc.page_content) > 300:
            snippet += "..."
        
        source_path = doc.metadata.get("source", "")
        doc_type = doc.metadata.get("type", "document")
        
        doc_url = generate_document_url(source_path, doc.page_content)
        
        if doc_type == "pdf":
            source_display = "–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –°–±–µ—Ä–±–∞–Ω–∫–∞"
        elif doc_type == "html":
            source_display = "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å —Å–∞–π—Ç–∞ –°–±–µ—Ä–±–∞–Ω–∫–∞"
        else:
            source_display = "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –°–±–µ—Ä–±–∞–Ω–∫–∞"
        
        sources.append(Source(
            source=source_display,
            snippet=snippet,
            relevance=1.0 - score,
            url=doc_url if is_valid_sber_url(doc_url) else None,
            document_type=doc_type
        ))
    
    return sources

def log_confidence_metrics(question: str, confidence: float, details: Dict):
    """–õ–æ–≥–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "question": question[:200],
        "confidence": confidence,
        "interpretation": details.get("interpretation", "unknown"),
        "priority": details.get("priority", "unknown"),
        "factors": details.get("factors", {})
    }
    
    logger.info(f"üìä –£–í–ï–†–ï–ù–ù–û–°–¢–¨: {confidence:.2%} - {details.get('interpretation', 'unknown')}")
    
    try:
        log_file = "confidence_metrics.log"
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ñ–∞–π–ª: {e}")

# =====================
# –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ FastAPI
# =====================
def create_app() -> FastAPI:
    app = FastAPI(
        title="SberBank Client Support AI Agent",
        version="3.0.0",
        description="AI-–∞–≥–µ–Ω—Ç –ø–µ—Ä–≤–æ–π –ª–∏–Ω–∏–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –°–±–µ—Ä–±–∞–Ω–∫–∞ —Å –æ—Ü–µ–Ω–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏",
    )
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI-–∞–≥–µ–Ω—Ç–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤...")
    logger.info(f"–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {CONFIDENCE_THRESHOLD:.0%}")
    
    try:
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        vectordb = FAISS.load_local(
            str(VECTOR_DB_DIR),
            embeddings,
            allow_dangerous_deserialization=True,
        )
        logger.info("–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
        raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π: {e}")
    
    try:
        llm = ChatOllama(
            model="llama3.2",
            temperature=0.1,
            seed=42,
            timeout=30.0
        )
        logger.info("AI –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ AI: {e}")
        raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ AI –º–æ–¥–µ–ª–∏: {e}")
    
    @app.get("/")
    async def root():
        return {
            "service": "AI Agent - First Line Support for SberBank Clients",
            "version": "3.0.0",
            "status": "active",
            "confidence_threshold": f"{CONFIDENCE_THRESHOLD:.0%}",
            "logic": "–ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å < 70% ‚Üí —ç—Å–∫–∞–ª–∞—Ü–∏—è –±–µ–∑ –æ—Ç–≤–µ—Ç–∞",
            "features": [
                "–û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞",
                "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —ç—Å–∫–∞–ª–∞—Ü–∏—è –ø—Ä–∏ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏",
                "–°—Å—ã–ª–∫–∏ –Ω–∞ —Å–∞–π—Ç –°–±–µ—Ä–±–∞–Ω–∫–∞",
                "–£–º–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É"
            ],
            "endpoints": {
                "ask": "POST /ask - –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ—Ç –ª–∏—Ü–∞ –∫–ª–∏–µ–Ω—Ç–∞",
                "health": "GET /health - –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏",
                "confidence_stats": "GET /confidence - –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"
            }
        }
    
    @app.get("/confidence")
    async def get_confidence_stats():
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞"""
        try:
            log_file = "confidence_metrics.log"
            if os.path.exists(log_file):
                with open(log_file, "r", encoding="utf-8") as f:
                    lines = f.readlines()[-100:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–∞–ø–∏—Å–µ–π
                
                if not lines:
                    return {"message": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –º–µ—Ç—Ä–∏–∫–∞—Ö"}
                
                metrics = [json.loads(line) for line in lines if line.strip()]
                
                confidences = [m.get("confidence", 0) for m in metrics]
                avg_confidence = sum(confidences) / len(confidences) if confidences else 0
                
                # –ü–æ–¥—Å—á–µ—Ç –ø–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è–º
                interpretations = {}
                for m in metrics:
                    interpretation = m.get("interpretation", "unknown")
                    interpretations[interpretation] = interpretations.get(interpretation, 0) + 1
                
                # –ü–æ–¥—Å—á–µ—Ç –ø–æ –ø–æ—Ä–æ–≥—É
                below_threshold = len([c for c in confidences if c < CONFIDENCE_THRESHOLD])
                above_threshold = len([c for c in confidences if c >= CONFIDENCE_THRESHOLD])
                
                return {
                    "total_entries": len(metrics),
                    "average_confidence": f"{avg_confidence:.2%}",
                    "threshold": f"{CONFIDENCE_THRESHOLD:.0%}",
                    "below_threshold": below_threshold,
                    "above_threshold": above_threshold,
                    "below_threshold_percentage": f"{(below_threshold/len(metrics))*100:.1f}%" if metrics else "0%",
                    "interpretation_distribution": interpretations,
                    "recent_confidence_scores": confidences[-10:],
                    "recent_questions": [
                        {"question": m.get("question_preview", m.get("question", "N/A")[:50]),
                         "confidence": m.get("confidence", 0)}
                        for m in metrics[-5:]
                    ]
                }
            return {"message": "–§–∞–π–ª –º–µ—Ç—Ä–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω"}
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {str(e)}")
    
    @app.post("/ask", response_model=Answer)
    async def ask(q: Question) -> Answer:
        """–û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤"""
        question = q.question.strip()
        
        if not question or len(question) < 3:
            raise HTTPException(
                status_code=400, 
                detail="–í–æ–ø—Ä–æ—Å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –≤–∞—à—É –ø—Ä–æ–±–ª–µ–º—É –ø–æ–¥—Ä–æ–±–Ω–µ–µ."
            )
        
        logger.info(f"üîç –í–û–ü–†–û–°: '{question}'")
        
        # 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        priority = detect_priority(llm, question)
        logger.info(f"üìä –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority}")
        
        # 2. –†–∞—Å—à–∏—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞
        expanded_queries = expand_query(llm, question)
        
        # 3. –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        all_docs_with_scores = []
        
        for query in expanded_queries:
            try:
                docs_scores = vectordb.similarity_search_with_score(query, k=10)
                all_docs_with_scores.extend(docs_scores)
                logger.debug(f"–ü–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –Ω–∞–π–¥–µ–Ω–æ {len(docs_scores)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}': {e}")
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_docs = {}
        for doc, score in all_docs_with_scores:
            content_start = doc.page_content[:200]
            doc_hash = hash(content_start)
            if doc_hash not in unique_docs or score < unique_docs[doc_hash][1]:
                unique_docs[doc_hash] = (doc, score)
        
        sorted_docs = sorted(unique_docs.values(), key=lambda x: x[1])
        
        if not sorted_docs:
            logger.warning("‚ùå –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π")
            # –ù–ï —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç - —Å—Ä–∞–∑—É —ç—Å–∫–∞–ª–∞—Ü–∏—è
            confidence = 0.1  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            confidence_details = {
                "calculation_time": datetime.now().isoformat(),
                "factors": {"no_documents": "–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"},
                "interpretation": "–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–Ω–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)"
            }
            
            # –í—Å–µ–≥–¥–∞ —ç—Å–∫–∞–ª–∏—Ä—É–µ–º –µ—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç
            needs_escalation = True
            escalation_reason = "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –≤–æ–ø—Ä–æ—Å—É –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"
            
            escalation_level, level_reason = get_escalation_level(priority, confidence)
            answer_text, final_route = generate_low_confidence_response(
                priority, confidence, f"{escalation_reason}. {level_reason}"
            )
            
            return Answer(
                answer=answer_text,
                sources=[],
                priority=priority.lower(),
                route_to=final_route,
                judge_reason=f"–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. {escalation_reason}",
                confidence=confidence,
                confidence_details=confidence_details,
                confidence_interpretation="–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–Ω–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)",
                confidence_below_threshold=True
            )
        
        logger.info(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(sorted_docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        
        # 4. –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        context_parts = []
        used_docs = []
        
        for doc, score in sorted_docs:
            if score > 0.95:  # –°–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                continue
            
            if not context_supports_question(doc.page_content, question, min_matches=1):
                continue
            
            context_parts.append(doc.page_content)
            used_docs.append((doc, score))
            
            if len('\n\n'.join(context_parts)) > 3500:
                break
            
            if len(context_parts) >= 5:
                break
        
        if not context_parts:
            logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            # –í—Å–µ–≥–¥–∞ —ç—Å–∫–∞–ª–∏—Ä—É–µ–º –µ—Å–ª–∏ –Ω–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            confidence = 0.2  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            confidence_details = {
                "calculation_time": datetime.now().isoformat(),
                "factors": {"no_relevant_documents": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"},
                "interpretation": "–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–Ω–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)"
            }
            
            needs_escalation = True
            escalation_reason = "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É"
            
            escalation_level, level_reason = get_escalation_level(priority, confidence)
            answer_text, final_route = generate_low_confidence_response(
                priority, confidence, f"{escalation_reason}. {level_reason}"
            )
            
            return Answer(
                answer=answer_text,
                sources=[],
                priority=priority.lower(),
                route_to=final_route,
                judge_reason=f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. {escalation_reason}",
                confidence=confidence,
                confidence_details=confidence_details,
                confidence_interpretation="–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–Ω–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)",
                confidence_below_threshold=True
            )
        
        context = "\n\n".join(context_parts)
        logger.info(f"üìù –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {len(context_parts)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞")
        
        # 5. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –ù–ê –û–°–ù–û–í–ê–ù–ò–ò –ö–û–ù–¢–ï–ö–°–¢–ê
        try:
            answer_chain = ANSWER_PROMPT | llm | StrOutputParser()
            answer_text = answer_chain.invoke({
                "context": context,
                "question": question
            }).strip()
            
            logger.info(f"ü§ñ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–æ–π {len(answer_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            answer_text = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É 900."
        
        # 6. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ—Ç–≤–µ—Ç–µ
        confidence, confidence_details, interpretation = calculate_confidence(
            used_docs, question, answer_text, context, priority
        )
        
        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        log_confidence_metrics(question, confidence, confidence_details)
        
        # 7. –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        needs_escalation, escalation_reason = needs_immediate_escalation(confidence, priority)
        
        if needs_escalation:
            # üî¥ –ù–ò–ó–ö–ê–Ø –£–í–ï–†–ï–ù–ù–û–°–¢–¨ - –≠–°–ö–ê–õ–ê–¶–ò–Ø –ë–ï–ó –û–¢–í–ï–¢–ê
            logger.warning(f"üö® –ù–ò–ó–ö–ê–Ø –£–í–ï–†–ï–ù–ù–û–°–¢–¨ ({confidence:.1%} < {CONFIDENCE_THRESHOLD:.0%}) - –≠–°–ö–ê–õ–ê–¶–ò–Ø")
            
            escalation_level, level_reason = get_escalation_level(priority, confidence)
            answer_text, final_route = generate_low_confidence_response(
                priority, confidence, escalation_reason
            )
            
            sources = []  # –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø—Ä–∏ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            
            return Answer(
                answer=answer_text,
                sources=sources,
                priority=priority.lower(),
                route_to=final_route,
                judge_reason=f"–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ—Ç–≤–µ—Ç–µ. {escalation_reason}",
                confidence=confidence,
                confidence_details=confidence_details,
                confidence_interpretation=interpretation,
                confidence_below_threshold=True
            )
        
        # 8. –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –í–´–®–ï –ø–æ—Ä–æ–≥–∞ - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
        logger.info(f"‚úÖ –£–í–ï–†–ï–ù–ù–û–°–¢–¨ –í–´–®–ï –ü–û–†–û–ì–ê ({confidence:.1%} >= {CONFIDENCE_THRESHOLD:.0%})")
        
        # 9. –û—Ü–µ–Ω–∏–≤–∞–µ–º, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –º—ã –æ—Ç–≤–µ—Ç–∏–ª–∏ –∏ –Ω—É–∂–µ–Ω –ª–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –ü–û–°–õ–ï –æ—Ç–≤–µ—Ç–∞
        judge_result = judge_answer(
            llm=llm,
            question=question,
            answer=answer_text,
            context=context[:1500],
            priority=priority
        )
        
        helped = judge_result.get("helped", True)
        final_priority = judge_result.get("priority", priority.lower())
        
        # 10. –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å URL
        sources = []
        if helped and used_docs:
            sources = format_sources(used_docs)
        
        # 11. –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –∫ –æ—Ç–≤–µ—Ç—É
        if sources and any(source.url for source in sources):
            urls = [source.url for source in sources if source.url]
            if urls:
                links_text = "\n\nüîó **–ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏:**\n"
                for i, url in enumerate(urls[:3], 1):
                    links_text += f"{i}. {url}\n"
                answer_text += links_text
        
        # 12. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é (–µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞)
        route_to = judge_result.get("route_to")
        
        # –î–ª—è high –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ –≤—Å–µ —Ä–∞–≤–Ω–æ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∏—Ä—É–µ–º –Ω–∞ L3
        if final_priority == "high" and not route_to:
            route_to = "L3"
            judge_result["reason"] = "–í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤–æ–ø—Ä–æ—Å–∞ —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–º"
        
        if route_to:
            logger.info(f"üîÑ –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –Ω–∞ {route_to} –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞")
        else:
            logger.info("üéØ –ê–≥–µ–Ω—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–ø—Ä–∞–≤–∏–ª—Å—è —Å –≤–æ–ø—Ä–æ—Å–æ–º")
        
        return Answer(
            answer=answer_text,
            sources=sources,
            priority=final_priority,
            route_to=route_to,
            judge_reason=judge_result.get("reason", "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞"),
            confidence=confidence,
            confidence_details=confidence_details,
            confidence_interpretation=interpretation,
            confidence_below_threshold=False
        )
    
    @app.get("/health")
    async def health_check():
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞"""
        try:
            test_response = llm.invoke("–ü—Ä–∏–≤–µ—Ç")
            return {
                "status": "healthy",
                "service": "SberBank Client Support AI",
                "llm": "available",
                "vectordb": "loaded",
                "confidence_threshold": f"{CONFIDENCE_THRESHOLD:.0%}",
                "logic": f"–≠—Å–∫–∞–ª–∞—Ü–∏—è –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å < {CONFIDENCE_THRESHOLD:.0%}",
                "message": "–°–µ—Ä–≤–∏—Å –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏"
            }
        except Exception as e:
            return {
                "status": "unhealthy",
                "service": "SberBank Client Support AI",
                "error": str(e),
                "llm": "unavailable",
                "message": "–¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama"
            }
    
    @app.get("/debug/confidence/{question}")
    async def debug_confidence(question: str):
        """Endpoint –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ —Ä–∞—Å—á–µ—Ç–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
        try:
            # –ò—â–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
            docs_with_scores = vectordb.similarity_search_with_score(question, k=5)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
            if docs_with_scores:
                context = "\n".join([doc.page_content for doc, _ in docs_with_scores[:3]])
                answer_chain = ANSWER_PROMPT | llm | StrOutputParser()
                answer = answer_chain.invoke({"context": context, "question": question})
            else:
                context = ""
                answer = "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
            priority = detect_priority(llm, question)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            confidence, details, interpretation = calculate_confidence(
                docs_with_scores, question, answer, context, priority
            )
            
            return {
                "question": question,
                "priority": priority,
                "confidence": confidence,
                "interpretation": interpretation,
                "above_threshold": confidence >= CONFIDENCE_THRESHOLD,
                "threshold": CONFIDENCE_THRESHOLD,
                "details": details,
                "documents_found": len(docs_with_scores),
                "sample_documents": [
                    {
                        "relevancy": 1.0 - score,
                        "score": score,
                        "preview": doc.page_content[:200] + "..."
                    }
                    for doc, score in docs_with_scores[:3]
                ] if docs_with_scores else [],
                "answer_preview": answer[:500]
            }
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ—Ç–ª–∞–¥–∫–∏: {str(e)}")
    
    return app

app = create_app()
